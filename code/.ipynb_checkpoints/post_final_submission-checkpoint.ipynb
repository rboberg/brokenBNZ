{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Final Project Submission\n",
    "### Ross Boberg, Sarah Neff, Sam Zaiss\n",
    "\n",
    "This notebook documents our exploration for the <a href=\"http://www.kaggle.com/c/random-acts-of-pizza\">Random Acts of Pizza</a> kaggle competition as part of the W207 Machine Learning course for UC Berkeley's MIDS program. We document the individual areas of exploration that we completed for this project, followed by the larger model that pulled these explorations together.\n",
    "\n",
    "### Problem Description\n",
    "The goal of the Random Acts of Pizza kaggle projects is to translate requests for pizza on the Reddit group \"Random Acts of Pizza\" in to predictions of whether or not they those requests are fulfilled. The data includes the text request, split in to the title and body of requests for pizza, as well as metadata about the request.\n",
    "\n",
    "These metadata include:\n",
    "<ul>\n",
    "<li>time of request (UTC and local)\n",
    "<li>numeric data about user activity:\n",
    "    <ul>\n",
    "    <li> 'requester_account_age_in_days_at_request'\n",
    "    <li> 'requester_days_since_first_post_on_raop_at_request'\n",
    "    <li> 'requester_number_of_comments_at_request'\n",
    "    <li> 'requester_number_of_comments_in_raop_at_request'\n",
    "    <li> 'requester_number_of_posts_at_request'\n",
    "    <li> 'requester_number_of_posts_on_raop_at_request'\n",
    "    <li> 'requester_number_of_subreddits_at_request'\n",
    "    <li> 'requester_upvotes_minus_downvotes_at_request'\n",
    "    <li> 'requester_upvotes_plus_downvotes_at_request'\n",
    "    </ul>\n",
    "<li>subreddit groups of the user</li>\n",
    "<li>Reddit user id</li>\n",
    "<li>request id to identify the request in submission</li>\n",
    "</ul>\n",
    "\n",
    "There are 4040 samples of requests in the exposed data, 994 of which were successful.\n",
    "Theare are 1631 samples of unlabeled test data, that Kaggle will test our predictions on\n",
    "\n",
    "<a id=\"top\"></a>\n",
    "#### Table of Contents\n",
    "<ol>\n",
    "<li><a href=\"#part1\">Data Import and Base Methods</a></li>\n",
    "<li><a href=\"#part2\">Activity Features</a></li>\n",
    "<li><a href=\"#part3\">Text Bag of Words</a>\n",
    "<ul>\n",
    "<li>Simple</li>\n",
    "<li>L1 Feature Regularization</li>\n",
    "<li>Time</li><br/>\n",
    "</ul>\n",
    "</li>\n",
    "<li><a href=\"#part4\">Time Features</a></li>\n",
    "<li><a href=\"#part5\">Interesting Words &amp; Category Tags</a></li>\n",
    "<li><a href=\"#part6\">Request Quality</a></li>\n",
    "<li><a href=\"#part7\">Text Summary Features</a>\n",
    "</li>\n",
    "<li><a href=\"#part8\">Location Features</a></li>\n",
    "<li><a href=\"#part9\">Parts of Speech</a></li>\n",
    "<li><a href=\"#part10\">Subreddits</a></li>\n",
    "<li><a href=\"#part11\">Final, Composite Model</a></li>\n",
    "<br/>\n",
    "<li><a href=\"#part12\">Notes on Error Analysis</a></li>\n",
    "<li><a href=\"#part13\">Appendix - additional goodness</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>\n",
    "## 1. Data Import and Base Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import pandas as pd\n",
    "import scipy as scipy\n",
    "import datetime as dt\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import urlopen\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "#useful for text processing\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Helper methods that will be used often in this notebook\n",
    "# gets word vectors from GloVe trained on twitter\n",
    "from getwv import tokenvec\n",
    "from glove_tknz import glove_prep\n",
    "topdir = '../data/twitter/50d'\n",
    "dirdepth = 3\n",
    "# for example:\n",
    "#tokenvec(['a','the'],topdir,dirdepth)\n",
    "\n",
    "# Helper methods to pull and submit data:\n",
    "def load_json_file(path):\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def make_submission_csv(predictions, ids, submission_name, path = '../predictions'):\n",
    "    with open(path+'/'+submission_name+'.csv', 'w') as csvfile:\n",
    "        field_names = ['request_id', 'requester_received_pizza']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = field_names)\n",
    "        writer.writeheader()\n",
    "        csv_data = zip(ids, predictions)\n",
    "        for row in csv_data:\n",
    "            writer.writerow({field_names[0]:row[0], field_names[1]:int(row[1])})\n",
    "            \n",
    "            \n",
    "# Helper methods for pulling columns from the dataset:\n",
    "def name2index(df, names):\n",
    "    return_single = False\n",
    "    \n",
    "    if type(names) == type([]):\n",
    "       names = np.array(names)\n",
    "    elif type(names) != type(np.array([])):\n",
    "        names = np.array([names])\n",
    "        return_single = True \n",
    "    \n",
    "    inds = np.where(np.in1d(df.columns, np.array(names)))[0]\n",
    "    \n",
    "    return inds[0] if return_single else inds\n",
    "\n",
    "            \n",
    "# Helper methods that are focused on class rebalancing:\n",
    "def balance_samples(y, method='oversample', rseed=207):\n",
    "    class_counts = np.bincount(y)\n",
    "    np.random.seed(rseed)\n",
    "    \n",
    "    maxi = np.argmax(class_counts)\n",
    "    new_idx = np.argwhere(y==maxi)\n",
    "    \n",
    "    for i in range(len(class_counts)):\n",
    "        if i != maxi:\n",
    "            mult = class_counts[maxi]/class_counts[i]\n",
    "            rem = class_counts[maxi] - class_counts[i]*mult\n",
    "            idxi = np.argwhere(y==i)\n",
    "            np.random.shuffle(idxi)\n",
    "            for j in range(mult):\n",
    "                new_idx = np.vstack((new_idx,idxi))\n",
    "            new_idx = np.vstack((new_idx,idxi[:rem]))\n",
    "        \n",
    "    np.random.shuffle(new_idx)\n",
    "\n",
    "    return np.reshape(new_idx, (new_idx.shape[0],))\n",
    "\n",
    "def oversample_kfold(kf, y):\n",
    "    kf_over = []\n",
    "    for ti, di in kf:\n",
    "        yt = y[ti]\n",
    "        ti_over = ti[balance_samples(yt)]\n",
    "        kf_over.append((ti_over, di))\n",
    "    return kf_over\n",
    "\n",
    "# Helper methods for printing and scoring:\n",
    "def test_kfolds(X, y, kf, model, verbose=1, balance=False):\n",
    "    roc_auc_list = []\n",
    "    \n",
    "    for train_i, dev_i in kf:\n",
    "        if balance:\n",
    "            train_i_orig = train_i\n",
    "            y_train = y[train_i_orig]\n",
    "            train_i = train_i_orig[balance_samples(y_train)]\n",
    "        \n",
    "        \n",
    "        X_train = X[train_i]\n",
    "        X_dev = X[dev_i]\n",
    "\n",
    "        model.fit(X_train, y[train_i])\n",
    "\n",
    "        dev_pred = model.predict(X_dev)\n",
    "        \n",
    "        roc_auc_i = roc_auc_score(y[dev_i], dev_pred)\n",
    "        roc_auc_list.append(roc_auc_i)\n",
    "        if verbose > 1:\n",
    "            print('ROC AUC:',roc_auc_i)\n",
    "            \n",
    "    if verbose > 0:\n",
    "        print 'N: %d, Mean: %f, Median: %f, SD: %f' %(len(kf), np.mean(roc_auc_list), np.median(roc_auc_list), np.std(roc_auc_list))\n",
    "        \n",
    "    return roc_auc_list\n",
    "\n",
    "def print_scores(scores):\n",
    "    print 'N: %d, Mean: %f, Median: %f, SD: %f' %(len(scores), np.mean(scores), np.median(scores), np.std(scores))\n",
    "\n",
    "\n",
    "# Lastly, some classes to handle string tokenizing that we will use in multiple sections:\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "class SnowballStemTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.stmr = SnowballStemmer('english')\n",
    "    def __call__(self, doc):\n",
    "        return [self.stmr.stem(t) for t in word_tokenize(doc)]\n",
    "    \n",
    "class PorterStemTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.stmr = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.stmr.stem(t) for t in word_tokenize(doc)]\n",
    "\n",
    "class PuncTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.reg = RegexpTokenizer(r'[\\s\\.\\,\\:\\-\\;\\(\\)\\[\\]\\{\\}\\!\\?]+',gaps=True)\n",
    "    def __call__(self, doc):\n",
    "        return self.reg.tokenize(doc)\n",
    "    \n",
    "class SpaceTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.tknzr = WhitespaceTokenizer()\n",
    "    def __call__(self, doc):\n",
    "        return [t for t in self.tknzr.tokenize(doc)]\n",
    "\n",
    "class PTBTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.tknzr = TreebankWordTokenizer()\n",
    "    def __call__(self, doc):\n",
    "        return [t for t in self.tknzr.tokenize(doc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets up the problem. We set the random seed to 207 (the class listing #!) so our results are replicable. We also shuffle our training data to make sure there are no issues of ordering that confuse the learning algorithms (e.g. all the postiive examples at the beginning). The training data has some variables that the submission data does not, so we make sure to ignore those because they will be useless for prediction.\n",
    "\n",
    "We also set up the K-folds we will use for cross validation in the rest of the notebook. We declare it now to allow us to get consistent results on our experiments. We use 10 fold validation (train our model on 90% of our data and testing it on the other 10%, on each non overlapping 10% of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Set up the training and test data to work with throughout the notebook:\n",
    "rseed = 207\n",
    "np.random.seed(rseed)\n",
    "\n",
    "# load data from JSON file as list of dicts\n",
    "all_train_dict_list = load_json_file('../data/train.json')\n",
    "submit_dict_list =  load_json_file('../data/test.json')\n",
    "\n",
    "n_all = len(all_train_dict_list)\n",
    "n_submit = len(submit_dict_list)\n",
    "\n",
    "# shuffle data to avoid biased splits of train / dev data\n",
    "rand.shuffle(sorted(all_train_dict_list, key=lambda k: k['request_id']))\n",
    "\n",
    "# process labels\n",
    "all_train_labels = np.array([x['requester_received_pizza'] for x in all_train_dict_list])\n",
    "\n",
    "# pandas is useful for turning dicts in to matrix-like objects\n",
    "# where each column is an numpy array\n",
    "submit_df = pd.DataFrame(submit_dict_list)\n",
    "all_train_df = pd.DataFrame(all_train_dict_list)\n",
    "\n",
    "# limit train to columns available in submit_df\n",
    "submit_cols = submit_df.columns\n",
    "all_train_df = all_train_df[submit_cols]\n",
    "\n",
    "# useful for sklearn scoring\n",
    "roc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "# set up kFolds to be used in the rest of the project\n",
    "kf = KFold(n_all, n_folds = 10, random_state=rseed)\n",
    "\n",
    "y = all_train_labels\n",
    "kf_over = oversample_kfold(kf, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2\"></a>\n",
    "## 2. Activity Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Set up Numeric Activity Variables, including processor class for all activity feature analysis.\n",
    "\n",
    "ACTIVITY_VARS = ['requester_account_age_in_days_at_request',\n",
    "                'requester_days_since_first_post_on_raop_at_request',\n",
    "                'requester_number_of_comments_at_request',\n",
    "                'requester_number_of_comments_in_raop_at_request',\n",
    "                'requester_number_of_posts_at_request',\n",
    "                'requester_number_of_posts_on_raop_at_request',\n",
    "                'requester_number_of_subreddits_at_request',\n",
    "                'requester_upvotes_minus_downvotes_at_request',\n",
    "                'requester_upvotes_plus_downvotes_at_request'\n",
    "                ]\n",
    "ACTIVITY_COLUMNS = name2index(all_train_df, ACTIVITY_VARS)\n",
    "\n",
    "class ExtractColumnsTransformer(TransformerMixin):\n",
    "    \n",
    "    def __init__(self, cols=[0]):\n",
    "        self.cols = cols\n",
    "        \n",
    "    def fit(self, *args, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        cols = self.cols\n",
    "        return X[:,cols]\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "\n",
    "class ExtractActivities(ExtractColumnsTransformer):\n",
    "    def __init__(self):\n",
    "        ExtractColumnsTransformer.__init__(self, ACTIVITY_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model for testing the activities demonstrates the importance of accounting for unbalanced classes in this problem.\n",
    "With no adjustment, the model has zero value.\n",
    "\n",
    "We adjust via two methods, either the class_weight parameter if the estimator has it, which weights errors of the less frequent class higher ot make sure the model actually tries to predict them, or by oversampling the minority class in the training set. The function that adjusts the k-folds to do that is at the beginning of the notebook: oversample_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal Class Weights\n",
      "N: 10, Mean: 0.508836, Median: 0.509778, SD: 0.007667\n",
      "\n",
      "Reweighted Classes\n",
      "N: 10, Mean: 0.558866, Median: 0.556987, SD: 0.021346\n",
      "\n",
      "Rebalanced Sample\n",
      "N: 10, Mean: 0.555097, Median: 0.563723, SD: 0.024857\n"
     ]
    }
   ],
   "source": [
    "### Explore models using the activity features only.\n",
    "\n",
    "# The main concern here is weighting classes appropriately, so we do an investigation of different\n",
    "# approaches and see how well the resulting model performs on 10 folds of the training data.\n",
    "\n",
    "print 'Equal Class Weights'\n",
    "pipe = Pipeline([('activity',ExtractActivities()), ('scale', StandardScaler()),('svc', SVC(random_state=rseed))])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "print '\\nReweighted Classes'\n",
    "wt_pipe = Pipeline([('activity',ExtractActivities()), ('scale', StandardScaler()),('svc', SVC(random_state=rseed, class_weight='auto'))])\n",
    "print_scores(cross_val_score(wt_pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "print '\\nRebalanced Sample'\n",
    "rebal_pipe = Pipeline([('activity',ExtractActivities()), ('scale', StandardScaler()),('svc',SVC(random_state=rseed))])\n",
    "\n",
    "# oversample training data in kfolds - function defined above\n",
    "# necessary for some estimators that don't have class weight parameters\n",
    "kf_over = oversample_kfold(kf, all_train_labels)\n",
    "print_scores(cross_val_score(rebal_pipe, all_train_df.values, all_train_labels, cv=kf_over, scoring=roc_scorer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Table += Activity Features\n",
    "\n",
    "The following table documents our results so far. The mean and median scores come from taking the averge of the ROC-AUC scores from 10 k-folds in the specified model.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Activity Features with Reweighted Classes</td>\n",
    "<td>0.5589</td>\n",
    "<td>0.5570</td>\n",
    "<td>0.0213</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3\"></a>\n",
    "## 3. Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3a. Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Define quick classes that we can use to isolate the title and body columns in our data.\n",
    "TITLE_COLUMN = name2index(all_train_df, 'request_title')\n",
    "BODY_COLUMN = name2index(all_train_df, 'request_text_edit_aware')\n",
    "USER_NAME_COLUMN = name2index(all_train_df, 'requester_username')\n",
    "\n",
    "class ExtractBody(ExtractColumnsTransformer):\n",
    "    def __init__(self):\n",
    "        ExtractColumnsTransformer.__init__(self, BODY_COLUMN)\n",
    "        \n",
    "class ExtractTitle(ExtractColumnsTransformer):\n",
    "    def __init__(self):\n",
    "        ExtractColumnsTransformer.__init__(self, TITLE_COLUMN)\n",
    "        \n",
    "class ExtractAllText(ExtractColumnsTransformer):\n",
    "    def __init__(self):\n",
    "        ExtractColumnsTransformer.__init__(self, np.array([TITLE_COLUMN, BODY_COLUMN]))\n",
    "\n",
    "        \n",
    "class ExtractUser(ExtractColumnsTransformer):\n",
    "    def __init__(self):\n",
    "        ExtractColumnsTransformer.__init__(self, USER_NAME_COLUMN)\n",
    "\n",
    "\n",
    "class ConcatStringTransformer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "        \n",
    "    def fit(self, *args, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        \n",
    "        if len(X.shape) == 1:\n",
    "            return X\n",
    "        else:\n",
    "            n_feat = X.shape[1]\n",
    "            new_list = []\n",
    "            for i in range(X.shape[0]):\n",
    "                new_list.append('.'.join(X[i,:]))\n",
    "            \n",
    "            return np.array(new_list)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "\n",
    "# Desparse Transformer, useful for sparse matrix to dense\n",
    "class DesparseTransformer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "        \n",
    "    def transform(self, X, **transform_params):\n",
    "        if (type(X) != type(np.array(1))):\n",
    "            return X.toarray()\n",
    "        \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        #do nothing\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "    \n",
    "def rejoin(l0,l1=None):\n",
    "    while len(l0) != 0:\n",
    "        if l1 is None:\n",
    "            l1 = []\n",
    "        if l0[0] == '<':\n",
    "            if len(l0) >= 3:\n",
    "                if l0[2] == '>':\n",
    "                    l1 += [l0.pop(0) + l0.pop(0) + l0.pop(0)]\n",
    "        else:\n",
    "            l1 += [l0.pop(0)]\n",
    "    return l1\n",
    "\n",
    "# Transforms a list of strings (docs) in to a list of token lists\n",
    "class TokenizeTransformer(TransformerMixin):\n",
    "    def __init__(self, tokenizer, rejoin_angle=True):\n",
    "        #self.tokenizer = np.vectorize(tokenizer)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.rejoin_angle = rejoin_angle\n",
    "        return None\n",
    "        \n",
    "    def transform(self, X, **transform_params):\n",
    "        if(not hasattr(X, '__iter__')): X = [X]\n",
    "        if self.rejoin_angle:\n",
    "            return [rejoin(self.tokenizer(Xi)) for Xi in X]\n",
    "        else:\n",
    "            return [self.tokenizer(Xi) for Xi in X]\n",
    "        \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        #do nothing\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "\n",
    "# preprocesses Twitter data ala GloVe\n",
    "class TwitterPrep(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.fprep = np.vectorize(glove_prep)\n",
    "        return None\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        return self.fprep(X)\n",
    "    \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        #do nothing\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "    \n",
    "# Transforms a list of lists of tokens in to a list of lists of word vectors\n",
    "class WordvecTransformer(TransformerMixin):\n",
    "    def __init__(self, topdir = '../data/twitter/50d', dirdepth = 3, d = 50, missing0 = True, nowarnings=True):\n",
    "        self.topdir = topdir\n",
    "        self.dirdepth = dirdepth\n",
    "        self.nowarnings = nowarnings\n",
    "        self.d = d\n",
    "        self.missing0 = missing0\n",
    "        return None\n",
    "        \n",
    "    def transform(self, X, **transform_params):\n",
    "        if(not hasattr(X, '__iter__')): X = [X]\n",
    "        return [tokenvec(Xi,self.topdir,self.dirdepth,nowarnings=self.nowarnings, d=self.d, missing0=self.missing0) for Xi in X]\n",
    "        \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        #do nothing\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "    \n",
    "class AverageWordvec(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        return np.array([np.mean(np.array(Xi), axis = 0) for Xi in X])\n",
    "    \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        #do nothing\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "    \n",
    "class MaxPool(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        return np.array([np.array(Xi).max(axis = 0) for Xi in X])\n",
    "    \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        #do nothing\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "\n",
    "class MinPool(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        return np.array([np.array(Xi).min(axis = 0) for Xi in X])\n",
    "    \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        #do nothing\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "\n",
    "# A simple text processing pipeline that we will use in the composite model:\n",
    "text_pipe = Pipeline([('union', ExtractAllText()), ('concat',ConcatStringTransformer())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "vectorize = Pipeline([('prep', TwitterPrep()),('tknzr', TokenizeTransformer(word_tokenize, rejoin_angle=True)),('wordvec', WordvecTransformer())])\n",
    "body_vecs = Pipeline([('body', ExtractBody()), ('vec', vectorize)]).fit_transform(X=all_train_df.values,y=1)\n",
    "title_vecs = Pipeline([('title', ExtractTitle()), ('vec', vectorize)]).fit_transform(X=all_train_df.values,y=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.88623,  1.2429 ,  0.79611, ...,  0.96793,  0.73626,  1.4947 ],\n",
       "       [ 0.74118,  1.0799 ,  0.93155, ...,  0.8378 ,  0.97903,  1.0717 ],\n",
       "       [ 0.92284,  1.2429 ,  0.96338, ...,  1.0747 ,  1.0325 ,  1.0629 ],\n",
       "       ..., \n",
       "       [ 1.394  ,  0.75963,  1.3985 , ...,  0.96793,  0.61673,  1.333  ],\n",
       "       [ 0.68661,  0.96413,  0.92151, ...,  1.1068 ,  0.61673,  1.2099 ],\n",
       "       [ 0.86806,  1.2429 ,  1.1981 , ...,  0.96793,  0.97903,  1.9487 ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MaxPool().fit_transform(X=body_vecs, y=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66263,  1.115  ,  0.16175, ...,  0.53718,  0.89124,  0.56035],\n",
       "       [ 0.58904,  1.115  ,  0.70831, ...,  1.0099 ,  0.27063,  1.0629 ],\n",
       "       [ 0.90566,  1.115  ,  0.79611, ...,  0.67343,  1.0325 ,  1.1652 ],\n",
       "       ..., \n",
       "       [ 0.90566,  1.115  ,  0.52945, ...,  0.48095,  0.53775,  0.72072],\n",
       "       [ 0.84921,  1.115  ,  0.60839, ...,  0.67343,  0.49569,  1.1652 ],\n",
       "       [ 0.86806,  1.3802 ,  0.52945, ...,  0.3087 ,  1.0958 ,  1.7472 ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MaxPool().fit_transform(X=title_vecs, y=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(class_weight='auto', C = 2, random_state=rseed)\n",
    "etc = ExtraTreesClassifier(n_estimators = 200,\n",
    "                           max_depth = 4,\n",
    "                           min_samples_split=15,\n",
    "                           random_state=rseed,\n",
    "                           class_weight='auto')\n",
    "gbc = GradientBoostingClassifier(n_estimators = 200,\n",
    "                            learning_rate=0.01,\n",
    "                           max_depth = 3,\n",
    "                           min_samples_split=10,\n",
    "                           random_state = rseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_avg = AverageWordvec().fit_transform(title_vecs, y=1)\n",
    "body_avg = AverageWordvec().fit_transform(body_vecs, y=1)\n",
    "title_max = MaxPool().fit_transform(title_vecs, y=1)\n",
    "body_max = MaxPool().fit_transform(body_vecs, y=1)\n",
    "title_min = MinPool().fit_transform(title_vecs, y=1)\n",
    "body_min = MinPool().fit_transform(body_vecs, y=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4040, 100)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((title_avg, body_avg),axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 10, Mean: 0.524357, Median: 0.528056, SD: 0.020923\n"
     ]
    }
   ],
   "source": [
    "print_scores(cross_val_score(Pipeline([('wvec', AverageWordvec()),('lsvc', lsvc)]), title_vecs, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 10, Mean: 0.556922, Median: 0.569829, SD: 0.023725\n"
     ]
    }
   ],
   "source": [
    "print_scores(cross_val_score(Pipeline([('wvec', AverageWordvec()),('lsvc', lsvc)]), body_vecs, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 10, Mean: 0.563426, Median: 0.564978, SD: 0.020924\n"
     ]
    }
   ],
   "source": [
    "print_scores(cross_val_score(Pipeline([('lsvc', lsvc)]), np.concatenate((title_avg, body_avg),axis=1), all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 10, Mean: 0.528041, Median: 0.533433, SD: 0.021987\n"
     ]
    }
   ],
   "source": [
    "print_scores(cross_val_score(Pipeline([('wvec', AverageWordvec()),('etc', etc)]), title_vecs, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 10, Mean: 0.573873, Median: 0.571756, SD: 0.016909\n"
     ]
    }
   ],
   "source": [
    "print_scores(cross_val_score(Pipeline([('wvec', AverageWordvec()),('etc', etc)]), body_vecs, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 10, Mean: 0.577718, Median: 0.567401, SD: 0.018882\n"
     ]
    }
   ],
   "source": [
    "print_scores(cross_val_score(Pipeline([('etc', etc)]), np.concatenate((title_avg, body_avg),axis=1), all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 10, Mean: 0.570818, Median: 0.566994, SD: 0.021885\n"
     ]
    }
   ],
   "source": [
    "print_scores(cross_val_score(Pipeline([('wvec', MaxPool()),('etc', etc)]), body_vecs, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 10, Mean: 0.574516, Median: 0.580037, SD: 0.021073\n"
     ]
    }
   ],
   "source": [
    "print_scores(cross_val_score(Pipeline([('wvec',FeatureUnion([('max', MaxPool()), ('min', MinPool())])),('etc', etc)]), body_vecs, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 10, Mean: 0.571173, Median: 0.580017, SD: 0.021725\n"
     ]
    }
   ],
   "source": [
    "print_scores(cross_val_score(Pipeline([('etc', etc)]), np.concatenate((title_max, body_max, title_min, body_min),axis=1), all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO / Notes\n",
    "<ul>\n",
    "<li>Look at success of title + body - not a major determinant of success or not\n",
    "<li>Try word vec vars with L1 regularization - did not add much value over body max + min with ETC\n",
    "<li> TODO: Implement a nonlinear layer over each word vector then max pool the results of that layer then pass to softmax / LR layer\n",
    "<li> TODO: Implement RCNN in Lai Et.Al 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenvec('mum',topdir,dirdepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Reusable method for quick BOW investigations:\n",
    "def simple_text(do_all=True, do_count=False,do_tfidf=False, do_titles=False, do_bodies=False, do_both=False, lowercase=False, tokenizer=None, stop_words=None):\n",
    "\n",
    "    # Notes\n",
    "    # results slightly better w/ lowercase = False (when unigrams only)\n",
    "    # bigrams added no value on unigrams\n",
    "\n",
    "    tv = TfidfVectorizer(ngram_range=(1,1),lowercase=lowercase, tokenizer=tokenizer, stop_words=stop_words)\n",
    "    cv = CountVectorizer(ngram_range=(1,1),lowercase=lowercase, tokenizer=tokenizer, stop_words=stop_words)\n",
    "    lsvc = LinearSVC(class_weight='auto', C = 2, random_state=rseed)\n",
    "    \n",
    "    body_cv = Pipeline([('body',ExtractBody()),('cv', cv)])\n",
    "    body_tv = Pipeline([('body',ExtractBody()),('tv', tv)])\n",
    "    \n",
    "    title_cv = Pipeline([('title',ExtractTitle()),('cv', cv)])\n",
    "    title_tv = Pipeline([('title',ExtractTitle()),('tv', tv)])\n",
    "\n",
    "    if do_titles or do_all:\n",
    "        if do_count or do_all:\n",
    "            # Count Vectorizer Titles\n",
    "            print '\\nCount Vectorizer on Titles'\n",
    "            \n",
    "            pipe = Pipeline([('tranform',title_cv),('model',lsvc)])\n",
    "            print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "        if do_tfidf or do_all:\n",
    "            # TFIDF Vectorizer TItles\n",
    "            print '\\nTFIDF Vectorizer on Titles'\n",
    "            \n",
    "            pipe = Pipeline([('tranform',title_tv),('model',lsvc)])\n",
    "            print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "\n",
    "    if do_bodies or do_all:\n",
    "        if do_count or do_all:\n",
    "            # Count Vectorizer Bodies\n",
    "            print '\\nCount Vectorizer on Bodies'\n",
    "            \n",
    "            pipe = Pipeline([('tranform',body_cv),('model',lsvc)])\n",
    "            print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "\n",
    "        if do_tfidf or do_all:\n",
    "            # TFIDF Vectorizer Bodies\n",
    "            print '\\nTFIDF Vectorizer on Bodies'\n",
    "            \n",
    "            pipe = Pipeline([('tranform',body_tv),('model',lsvc)])\n",
    "            print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "        \n",
    "    if do_both or do_all:\n",
    "        if do_count or do_all:\n",
    "\n",
    "            # Count Vectorizer Titles and Bodies\n",
    "            print '\\nCount Vectorizer on Titles and Bodies'\n",
    "            \n",
    "            pipe = Pipeline([\n",
    "                ('features',FeatureUnion([\n",
    "                    ('tranform_title',title_cv),\n",
    "                    ('tranform_body',body_cv)\n",
    "                ])),\n",
    "                ('model',lsvc)])\n",
    "            print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "            \n",
    "        if do_tfidf or do_all:\n",
    "            # TFIDF Vectorizer Titles and Bodies\n",
    "            print '\\nTFIDF Vectorizer on Titles and Bodies'\n",
    "            \n",
    "            pipe = Pipeline([\n",
    "                ('features',FeatureUnion([\n",
    "                    ('tranform_title',title_tv),\n",
    "                    ('tranform_body',body_tv)\n",
    "                ])),\n",
    "                ('model',lsvc)])\n",
    "            print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our text model counts how many times each word in a vocabulary (learned from the text) is present in each request. We adjust that term frequency by inverse document frequency (how often that term occurs throughout the document) to overweight uncommon words, which often have more explanatory power.\n",
    "\n",
    "We also play around with a few different tokenizers to see which get the best results. These tokenizers turn lots of text (like pizza requests) in to a series of words (tokens). The tokens can be \"stemmed\" which adjusts the word so that, for example, different tenses of the same verb have the same representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Experimentation with different tokenizers\n",
    "\n",
    "print \"Examination of best vectorizer:\"\n",
    "\n",
    "print '\\nDefault Vectorizer:'\n",
    "simple_text(do_all = False, do_both=True, do_tfidf=True, do_count=True)\n",
    "\n",
    "print '=================='\n",
    "\n",
    "print 'Examination of best tokenizer'\n",
    "\n",
    "print \"\\nSnowball Stem Tokenizer:\"\n",
    "simple_text(do_all=False, do_both=True, do_tfidf=True, tokenizer=SnowballStemTokenizer())\n",
    "\n",
    "print \"\\Lemma Tokenizer:\"\n",
    "simple_text(do_all=False, do_both=True, do_tfidf=True, tokenizer=LemmaTokenizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Table += Simple Bag of Words\n",
    "\n",
    "The following table documents our results so far. The mean and median scores come from taking the averge of the ROC-AUC scores from 10 k-folds in the specified model.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Activity Features with Reweighted Classes</td>\n",
    "<td>0.5589</td>\n",
    "<td>0.5570</td>\n",
    "<td>0.0213</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Simple BOW, Titles + Bodies, Snowball Stem Tokenizer</td>\n",
    "<td>0.5615</td>\n",
    "<td>0.5604</td>\n",
    "<td>0.0243</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. L1 Feature Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Reusable class to process important terms\n",
    "class LinearWeightFeatureThreshold(TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model = LinearSVC(class_weight='auto', loss='squared_hinge', penalty='l1', dual=False, random_state=rseed),\n",
    "        return_dense = True, #dense or sparse matrix\n",
    "        C = 1, # C for L1\n",
    "        threshold = 0.01, # threshold to keep\n",
    "        verbose = 1 #tell how many features were kept\n",
    "        ):\n",
    "        self.model = model\n",
    "        self.return_dense = return_dense\n",
    "        self.C = C\n",
    "        self.threshold = threshold\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        model = self.model\n",
    "        threshold = self.threshold\n",
    "        verbose = self.verbose\n",
    "        C = self.C\n",
    "        \n",
    "        model.set_params(C=C)\n",
    "        \n",
    "        model.fit(X, y)\n",
    "        \n",
    "        # check which coefficients to keep\n",
    "        coef = model.coef_\n",
    "        sig_coef = (np.abs(coef) > threshold)[0]\n",
    "        n_coef = np.sum(sig_coef)\n",
    "        \n",
    "        \n",
    "        if verbose > 0:\n",
    "            print 'kept %d/%d features' % (n_coef, coef.shape[1])\n",
    "        \n",
    "        # so we never return an empty vector if C was too low\n",
    "        if n_coef == 0:\n",
    "            sig_coef[0] = 1\n",
    "        \n",
    "        # save the significant coefficients\n",
    "        self.sig_coef_  = sig_coef\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        sig_coef = self.sig_coef_\n",
    "        return_dense = self.return_dense\n",
    "        \n",
    "        X_new = X[:,sig_coef]\n",
    "        \n",
    "        if return_dense and (type(X_new) != type(np.array(1))):\n",
    "            X_new = X_new.toarray()\n",
    "            \n",
    "        return X_new\n",
    "    \n",
    "    # methods needed to make this grid searchable\n",
    "    def get_params(self, deep=True):\n",
    "        # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
    "        return {'C':self.C, 'threshold':self.threshold}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text models above result in lots of variables, many of which will be completely useless. This noise can overwhelm the models, so we want to find ways to \"regularize\" or reduce the number of variables to only significant ones. We do this by \"L1\" regularization. L1 regularizaiton uses a model that calculates linear errors, which happens to result in a sparse number of variables actually used. We take the variables that were used in this sparser model, then feed them in to a model that uses squared errors, to get better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found L1 regularization with a Linear SVC to be an effective method for reducing the number features, especially coming out of term frequency matrices. We chose C=0.15 ('regularization' term that controls how sparse the variables in the model are) via grid search (by trying lots of different values and seeing what does best), and it tends to return about 40 features on our sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Try ExtraTreesClassifier for the BOW models:\n",
    "\n",
    "# C=0.15 arrived at via grid search, but took a long time so not included here.\n",
    "l1 = LinearWeightFeatureThreshold(C=0.15)\n",
    "tv = TfidfVectorizer(tokenizer=SnowballStemTokenizer())\n",
    "lsvc = LinearSVC(class_weight='auto', C = 2, random_state=rseed)\n",
    "\n",
    "etc = ExtraTreesClassifier(n_estimators = 200,\n",
    "                           max_depth = 4,\n",
    "                           min_samples_split=15,\n",
    "                           random_state=rseed,\n",
    "                           class_weight='auto')\n",
    "\n",
    "pipe_lsvc = Pipeline([('extract', ExtractBody()), ('tv',tv), ('features',l1), ('clf',lsvc)])\n",
    "pipe_etc = Pipeline([('extract', ExtractBody()), ('tv',tv), ('features',l1), ('clf',etc)])\n",
    "\n",
    "\n",
    "print '\\nL1 Feature Reduction on Bodies w/ LSVC'\n",
    "print_scores(cross_val_score(pipe_lsvc, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "print '\\nL1 Feature Reduction on Bodies w/ ETC'\n",
    "tv = TfidfVectorizer(tokenizer=SnowballStemTokenizer())\n",
    "lsvc = LinearSVC(class_weight='auto', C = 2, random_state=rseed)\n",
    "\n",
    "etc = ExtraTreesClassifier(n_estimators = 200,\n",
    "                           max_depth = 4,\n",
    "                           min_samples_split=15,\n",
    "                           random_state=rseed,\n",
    "                           class_weight='auto')\n",
    "\n",
    "print_scores(cross_val_score(pipe_etc, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Table += Bag of Words w/ Feature Reduction\n",
    "\n",
    "The following table documents our results so far. The mean and median scores come from taking the averge of the ROC-AUC scores from 10 k-folds in the specified model.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Activity Features with Reweighted Classes</td>\n",
    "<td>0.5589</td>\n",
    "<td>0.5570</td>\n",
    "<td>0.0213</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Simple BOW, Titles + Bodies, Snowball Stem Tokenizer</td>\n",
    "<td>0.5615</td>\n",
    "<td>0.5604</td>\n",
    "<td>0.0243</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees BOW w/ L1 Feature Reduction Bodies</td>\n",
    "<td>0.5870</td>\n",
    "<td>0.5920</td>\n",
    "<td>0.0271</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part4\"></a>\n",
    "## 4. Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Reusable class for time features\n",
    "### Reusable class for time features\n",
    "DATE_TIME_COLUMN_DEFAULT = np.where(all_train_df.columns == 'unix_timestamp_of_request')[0][0]\n",
    "\n",
    "class TimeTransformer(TransformerMixin):\n",
    "    \n",
    "    def __init__(self, date_time_column=DATE_TIME_COLUMN_DEFAULT, do_second=True, do_minute=True, do_hour=True, do_dow=True, do_day=True, do_month=True):\n",
    "        self.date_time_column = date_time_column\n",
    "        self.do_second = do_second\n",
    "        self.do_minute = do_minute\n",
    "        self.do_hour = do_hour\n",
    "        self.do_dow = do_dow\n",
    "        self.do_day = do_day\n",
    "        self.do_month = do_month\n",
    "        \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def extract_from_date_time_(self, dt, do_second, do_minute, do_hour, do_dow, do_day, do_month):\n",
    "        extract = []\n",
    "        if do_second:\n",
    "            extract.append(dt.second)\n",
    "        \n",
    "        if do_minute:\n",
    "            extract.append(dt.minute)\n",
    "            \n",
    "        if do_hour:\n",
    "            extract.append(dt.hour)\n",
    "            \n",
    "        if do_dow:\n",
    "            extract.append(dt.weekday())\n",
    "            \n",
    "        if do_day:\n",
    "            extract.append(dt.day)\n",
    "            \n",
    "        if do_month:\n",
    "            extract.append(dt.month)\n",
    "            \n",
    "        return extract\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        date_time_column = self.date_time_column\n",
    "        do_second = self.do_second\n",
    "        do_minute = self.do_minute\n",
    "        do_hour = self.do_hour\n",
    "        do_dow = self.do_dow\n",
    "        do_day = self.do_day\n",
    "        do_month = self.do_month\n",
    "        extract_from_date_time = self.extract_from_date_time_\n",
    "        \n",
    "        features = np.array([\n",
    "            extract_from_date_time(dt.datetime.fromtimestamp(timei),\n",
    "                                   do_second=do_second,\n",
    "                                   do_minute=do_minute,\n",
    "                                   do_hour=do_hour,\n",
    "                                   do_dow=do_dow,\n",
    "                                   do_day=do_day,\n",
    "                                   do_month=do_month) for timei in X[:,date_time_column]\n",
    "        ])\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'do_second':self.do_second,\n",
    "                'do_minute':self.do_minute,\n",
    "                'do_hour':self.do_hour,\n",
    "                'do_dow':self.do_dow,\n",
    "                'do_day':self.do_day,\n",
    "                'do_month':self.do_month}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Time Variables\n",
    "\n",
    "We create several features derived from the date & time, visualize them here, and see how they perfrom in a simple model on their own. We checked each time transformation against logistic regression (a linear model) and a tree ensemble (a nonlinear model), because a linear method might not capture all the information in time.\n",
    "\n",
    "Decision trees (a bunch of consecutive binary splits of the data based on variable values) can be a useful way to explore models where features my be nonlinear as may be the case with time features. For example, hour 23.5 (late at night) and 0.5 (so early in the morning it's still late at night) may be treated similarly by a linear model, but a decision tree, can create a couple splites and capture it easily (hour > 23 and hour < 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "lr = LogisticRegression(random_state=rseed, class_weight='auto', fit_intercept=True)\n",
    "etc = ExtraTreesClassifier(n_estimators=200,\n",
    "                           max_depth = 4,\n",
    "                           min_samples_split=15,\n",
    "                           random_state=rseed,\n",
    "                           class_weight='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Visualizations to inspect time variables\n",
    "# Exploring time features, it looks like requests are not as succesful at late nights /\n",
    "# early mornings or on Mondays / Fridays...\n",
    "# Though that could be because there's more requests on those days.\n",
    "\n",
    "tt = TimeTransformer(do_minute=False, do_day=False, do_second=False, do_hour=False, do_dow=False, do_month=True)\n",
    "print 'Logistic Regression:'\n",
    "print_scores(cross_val_score(Pipeline([('tt',tt),('model',lr)]), all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "print 'Extra Trees:'\n",
    "print_scores(cross_val_score(Pipeline([('tt',tt),('model',etc)]), all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "# look at month success\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "month = tt.transform(all_train_df.values).flatten()\n",
    "month_pos = month[all_train_labels]\n",
    "month_neg = month[np.logical_not(all_train_labels)]\n",
    "pd.Series(month_pos).hist(bins=12, alpha=0.2, normed=True, label='Winner Values Greater than All')\n",
    "pd.Series(month_neg).hist(bins=12, alpha=0.2, normed=True, label='Winner Values Less than All')\n",
    "plt.title(\"RAOP Month of Message Submissions \\n\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt = TimeTransformer(do_minute=False, do_day=True, do_second=False, do_hour=False, do_dow=False, do_month=False)\n",
    "print 'Logistic Regression:'\n",
    "print_scores(cross_val_score(Pipeline([('tt',tt),('model',lr)]), all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "print 'Extra Trees:'\n",
    "print_scores(cross_val_score(Pipeline([('tt',tt),('model',etc)]), all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "\n",
    "\n",
    "# look at day success\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "day = tt.transform(all_train_df.values).flatten()\n",
    "day_pos = day[all_train_labels]\n",
    "day_neg = day[np.logical_not(all_train_labels)]\n",
    "pd.Series(day_pos).hist(bins=31, alpha=0.2, normed=True, label='Winner Values Greater than All')\n",
    "pd.Series(day_neg).hist(bins=31, alpha=0.2, normed=True, label='Winner Values Less than All')\n",
    "plt.title(\"RAOP Day Message Submissions \\n\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt = TimeTransformer(do_minute=False, do_day=False, do_second=False, do_hour=False, do_dow=True, do_month=False)\n",
    "print 'Logistic Regression:'\n",
    "print_scores(cross_val_score(Pipeline([('tt',tt),('model',lr)]), all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "print 'Extra Trees:'\n",
    "print_scores(cross_val_score(Pipeline([('tt',tt),('model',etc)]), all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "\n",
    "# look at day of week success\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "dow = tt.transform(all_train_df.values).flatten()\n",
    "dow_pos = dow[all_train_labels]\n",
    "dow_neg = dow[np.logical_not(all_train_labels)]\n",
    "pd.Series(dow_pos).hist(bins=7, alpha=0.2, normed=True, label='Winner Values Greater than All')\n",
    "pd.Series(dow_neg).hist(bins=7, alpha=0.2, normed=True, label='Winner Values Less than All')\n",
    "plt.title(\"RAOP Day of Week Message Submissions \\n\")\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt = TimeTransformer(do_minute=False, do_day=False, do_second=False, do_hour=True, do_dow=False, do_month=False)\n",
    "print 'Logistic Regression:'\n",
    "print_scores(cross_val_score(Pipeline([('tt',tt),('model',lr)]), all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "print 'Extra Trees:'\n",
    "print_scores(cross_val_score(Pipeline([('tt',tt),('model',etc)]), all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "\n",
    "# look at hourly success\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "hour = tt.transform(all_train_df.values).flatten()\n",
    "hour_pos = hour[all_train_labels]\n",
    "hour_neg = hour[np.logical_not(all_train_labels)]\n",
    "pd.Series(hour_pos).hist(bins=24, alpha=0.2, normed=True, label='Winner Values Greater than All')\n",
    "pd.Series(hour_neg).hist(bins=24, alpha=0.2, normed=True, label='Winner Values Less than All')\n",
    "plt.title(\"RAOP Hour of Message Submissions \\n\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt = TimeTransformer(do_minute=True, do_day=False, do_second=False, do_hour=False, do_dow=False, do_month=False)\n",
    "print 'Logistic Regression:'\n",
    "print_scores(cross_val_score(Pipeline([('tt',tt),('model',lr)]), all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "print 'Extra Trees:'\n",
    "print_scores(cross_val_score(Pipeline([('tt',tt),('model',etc)]), all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "\n",
    "\n",
    "# look at minute success\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "minute = tt.transform(all_train_df.values).flatten()\n",
    "minute_pos = minute[all_train_labels]\n",
    "minute_neg = minute[np.logical_not(all_train_labels)]\n",
    "pd.Series(minute_pos).hist(bins=60, alpha=0.2, normed=True, label='Winner Values Greater than All')\n",
    "pd.Series(minute_neg).hist(bins=60, alpha=0.2, normed=True, label='Winner Values Less than All')\n",
    "plt.title(\"RAOP Minute of Message Submissions \\n\")\n",
    "plt.xlabel(\"Minute\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt = TimeTransformer(do_minute=False, do_day=False, do_second=True, do_hour=False, do_dow=False, do_month=False)\n",
    "print 'Logistic Regression:'\n",
    "print_scores(cross_val_score(Pipeline([('tt',tt),('model',lr)]), all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "print 'Extra Trees:'\n",
    "print_scores(cross_val_score(Pipeline([('tt',tt),('model',etc)]), all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "\n",
    "# look at second success\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "second = tt.transform(all_train_df.values).flatten()\n",
    "second_pos = second[all_train_labels]\n",
    "second_neg = second[np.logical_not(all_train_labels)]\n",
    "pd.Series(second_pos).hist(bins=60, alpha=0.2, normed=True, label='Winner Values Greater than All')\n",
    "pd.Series(second_neg).hist(bins=60, alpha=0.2, normed=True, label='Winner Values Less than All')\n",
    "plt.title(\"RAOP Second of Message Submissions \\n\")\n",
    "plt.xlabel(\"Second\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting Time Variables Together\n",
    "\n",
    "Months, day of the month, and hour of the day all appear to be at least somewhat effective predictors.\n",
    "It's worth noting that the hour of the message only adds value with the nonlinear classifier.\n",
    "This suggests our final classifier should be nonlinear if it includes this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Try a couple classifiers for time features to find a good choice.\n",
    "# Turns out time features don't perform well by themselves.\n",
    "\n",
    "etc = ExtraTreesClassifier(n_estimators=200,\n",
    "                           max_depth = 4,\n",
    "                           min_samples_split=15,\n",
    "                           random_state=rseed,\n",
    "                           class_weight='auto')\n",
    "\n",
    "# only do month, day, hour\n",
    "tt = TimeTransformer(do_minute=False, do_day=True, do_second=True, do_hour=False, do_dow=False, do_month=True)\n",
    "# the day was borderline, so try one without\n",
    "tt_noday = TimeTransformer(do_minute=False, do_day=False, do_second=True, do_hour=False, do_dow=False, do_month=True)\n",
    "\n",
    "print '\\nExtra Tree Ensemble Month, Day, Hour'\n",
    "\n",
    "etc_pipe = Pipeline([\n",
    "    ('time',tt),\n",
    "    ('model',etc)\n",
    "    ])\n",
    "\n",
    "print_scores(cross_val_score(etc_pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "print '\\nExtra Tree Ensemble Month, Hour'\n",
    "\n",
    "etc_pipe = Pipeline([\n",
    "    ('time',tt_noday),\n",
    "    ('model',etc)\n",
    "    ])\n",
    "\n",
    "print_scores(cross_val_score(etc_pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Table += Time Features\n",
    "\n",
    "The following table documents our results so far. The mean and median scores come from taking the averge of the ROC-AUC scores from 5 k-folds in the specified model.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Activity Features with Reweighted Classes</td>\n",
    "<td>0.5589</td>\n",
    "<td>0.5570</td>\n",
    "<td>0.0213</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Simple BOW, Titles + Bodies, Snowball Stem Tokenizer</td>\n",
    "<td>0.5615</td>\n",
    "<td>0.5604</td>\n",
    "<td>0.0243</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees BOW w/ L1 Feature Reduction Bodies</td>\n",
    "<td>0.5870</td>\n",
    "<td>0.5920</td>\n",
    "<td>0.0271</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Month, Hour</td>\n",
    "<td>0.5406</td>\n",
    "<td>0.5440</td>\n",
    "<td>0.0232</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part5\"></a>\n",
    "## 5. Interesting Words & Category Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Reusable class for interesting words\n",
    "TITLE_COLUMN = np.where(all_train_df.columns == 'request_title')[0][0]\n",
    "BODY_COLUMN = np.where(all_train_df.columns == 'request_text_edit_aware')[0][0]\n",
    "\n",
    "# Useful method for getting length of text:\n",
    "def lenArray(text, no_zero = True):\n",
    "    lens = np.array([[float(len(x.encode('utf-8'))) for x in text]]).T\n",
    "    lens[lens==0]=1\n",
    "    return lens\n",
    "\n",
    "class InterestingWordsTransformer(TransformerMixin):\n",
    "    def __init__(self, title_col = TITLE_COLUMN, body_col=BODY_COLUMN, do_title=True, do_body=True, do_tags=True, do_words=True):\n",
    "        self.do_title = do_title\n",
    "        self.do_body = do_body\n",
    "        self.do_tags = do_tags\n",
    "        self.do_words = do_words\n",
    "        self.title_col = title_col\n",
    "        self.body_col = body_col\n",
    "        \n",
    "        # dictionary of keys = tags and values = word to find\n",
    "        self.keywords = {\n",
    "            'sad_food': ['hungry', 'starving', 'no food', 'grocer', 'eaten', 'hunger', 'ramen', 'empty', 'fridge', 'refrig'],\n",
    "            'money': ['broke', 'paid', 'money', 'unemployed', 'lost', 'job', 'bill', 'wage', 'work', 'payday', 'paycheck', 'funds', 'cash', 'bank', 'laid off', 'poor', 'payroll'],\n",
    "            'sad': ['worst', 'awful', 'sick', 'problem', 'catch a break', 'cheer', 'hospital', 'bad', 'shitty', 'stress', 'luck', ':(', 'rough', 'tough', 'battle', 'reasons', 'losing'],\n",
    "            'military': ['military', 'veteran', 'soldier', 'army', 'navy', 'marine', 'air force', 'iraq', 'afghanis'],\n",
    "            'happy': ['celebrate', 'birthday', 'party', 'new year', 'bday', 'engage', 'annivers', 'surprise', 'loves', 'best'],\n",
    "            'nice': ['please', 'help', 'thank', ':)', 'helping', 'aid', 'exchange', 'spare', ':D',':-)'],\n",
    "            'honest': ['sob story', 'honest', 'just want', 'just because'],\n",
    "            'parent': ['family', 'kids', 'parent', 'mom', 'mommy', 'mother', 'dad', 'father', 'baby', 'boy', 'girl'],\n",
    "            'relationship': ['husband', 'wife', 'girlfriend', 'boyfriend', 'fianc', 'roommate', 'married'],\n",
    "            'test': ['study', 'test', 'final', 'midterm','student'],\n",
    "            'time': ['yesterday', 'lately', 'never', 'during', 'sunday', 'constantly']\n",
    "        }\n",
    "    \n",
    "    def find_tag_words(self, keywords, text):\n",
    "        word_dict = {}\n",
    "        tag_dict = {}\n",
    "\n",
    "        for tag, words in keywords.iteritems():\n",
    "\n",
    "            tag_count = None\n",
    "\n",
    "            for word in words:\n",
    "                # check for the word in the text\n",
    "                has_word = np.array([(1 if word in t else 0) for t in text])\n",
    "                word_dict[word] = has_word\n",
    "                \n",
    "                # count the words with the tag\n",
    "                if tag_count is None:\n",
    "                    tag_count = has_word\n",
    "                else:\n",
    "                    tag_count = tag_count +  has_word\n",
    "\n",
    "            tag_dict[tag] = tag_count\n",
    "\n",
    "        return (tag_dict, word_dict)\n",
    "    \n",
    "    # manually create keywords with categories\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        do_title = self.do_title\n",
    "        do_tags = self.do_tags\n",
    "        do_words = self.do_words\n",
    "        do_body = self.do_body\n",
    "        keywords = self.keywords\n",
    "        find_tag_words = self.find_tag_words\n",
    "        body_col = self.body_col\n",
    "        title_col = self.title_col\n",
    "        \n",
    "        features = []\n",
    "        feature_names = []\n",
    "\n",
    "        # find keywords and tags\n",
    "        if do_title and not do_body:\n",
    "            title_unicode = np.array([x.lower() for x in X[:,title_col]])\n",
    "            title_tag_dict, title_word_dict = find_tag_words(keywords, title_unicode)\n",
    "            \n",
    "            # normalize appearence of important words by character length of text\n",
    "            # because longer requests should have more hits\n",
    "            lens = lenArray(X[:,body_col])\n",
    "            \n",
    "            # add frequency of tags\n",
    "            if do_tags:\n",
    "                features.append(pd.DataFrame(title_tag_dict).values/lens)\n",
    "                feature_names.append('title_tags')\n",
    "                \n",
    "            # add frequency of words\n",
    "            if do_words:\n",
    "                features.append(pd.DataFrame(title_word_dict).values/lens)\n",
    "                feature_names.append('title_words')\n",
    "\n",
    "        if do_body and not do_title:\n",
    "            body_unicode = np.array([x.lower() for x in X[:,body_col]])\n",
    "            body_tag_dict, body_word_dict = find_tag_words(keywords, body_unicode)\n",
    "            \n",
    "            # normalize appearence of important words by character length of text\n",
    "            # because longer requests should have more hits\n",
    "            lens = lenArray(X[:,body_col])\n",
    "            \n",
    "            # add frequency of tags\n",
    "            if do_tags:\n",
    "                features.append(pd.DataFrame(body_tag_dict).values/lens)\n",
    "                feature_names.append('body_tags')\n",
    "            \n",
    "            # add frequency of words\n",
    "            if do_words:\n",
    "                features.append(pd.DataFrame(body_word_dict).values/lens)\n",
    "                feature_names.append('body_words')\n",
    "                \n",
    "        if do_body and do_title:\n",
    "            body_unicode = np.array([x.lower() for x in ConcatStringTransformer().transform(X[:,[body_col,title_col]])])\n",
    "            body_tag_dict, body_word_dict = find_tag_words(keywords, body_unicode)\n",
    "            \n",
    "            # normalize appearence of important words by character length of text\n",
    "            # because longer requests should have more hits\n",
    "            lens = lenArray(X[:,body_col])\n",
    "            \n",
    "            # add frequency of tags\n",
    "            if do_tags:\n",
    "                features.append(pd.DataFrame(body_tag_dict).values/lens)\n",
    "                feature_names.append('body_tags')\n",
    "            \n",
    "            # add frequency of words\n",
    "            if do_words:\n",
    "                features.append(pd.DataFrame(body_word_dict).values/lens)\n",
    "                feature_names.append('body_words')\n",
    "\n",
    "        return np.hstack(tuple(features))\n",
    "    \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        #do nothing\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'do_words': self.do_words, 'do_tags':self.do_tags, 'do_body':self.do_body, 'do_title':self.do_title}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section finds words that we thought were \"interesting\" (potentially explanatory) in request text. It also puts each word in to a category, because a request where someone bemoans their lack of money may include the workd \"broke\" or \"lost job\", but maybe only one of those too. Since the lack of money could be driving the response, we want to combine those features together. The interesting words and their categories are defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Explore different models focusing on interesting words in tags and text:\n",
    "\n",
    "etc = ExtraTreesClassifier(n_estimators = 200,\n",
    "                           max_depth = 4,\n",
    "                           min_samples_split=10,\n",
    "                           random_state=rseed,\n",
    "                           class_weight='auto')\n",
    "\n",
    "lsvc = Pipeline([('scale', StandardScaler()), ('clf', LinearSVC(class_weight='auto', random_state=rseed))])\n",
    "\n",
    "#lsvc_pca = Pipeline([\n",
    "#    ('scale', StandardScaler()),\n",
    "#    ('pca', RandomizedPCA(n_components=3,random_state=rseed)),\n",
    "#    ('clf', LinearSVC(class_weight='auto',random_state=rseed))\n",
    "#])\n",
    "\n",
    "\n",
    "models = {'Extra Trees':etc, 'Linear SVC':lsvc}\n",
    "\n",
    "print '\\n##############'\n",
    "print 'Body & Title Tags'\n",
    "trans = InterestingWordsTransformer(do_words=False)\n",
    "\n",
    "for name, model in models.iteritems():\n",
    "    print '\\n%s' % name\n",
    "    kfi = kf_over if (name=='Gradient Boosting') else kf\n",
    "    pipe = Pipeline([('trans',trans),('model',model)])\n",
    "    print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kfi, scoring=roc_scorer))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "print '\\n##############'\n",
    "print 'Body & Title Words'\n",
    "trans = InterestingWordsTransformer(do_tags=False)\n",
    "\n",
    "for name, model in models.iteritems():\n",
    "    print '\\n%s' % name\n",
    "    kfi = kf_over if (name=='Gradient Boosting') else kf\n",
    "    pipe = Pipeline([('trans',trans),('model',model)])\n",
    "    print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kfi, scoring=roc_scorer))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "print '\\n##############'\n",
    "print 'Body & Title Words & Tags'\n",
    "trans = InterestingWordsTransformer()\n",
    "\n",
    "for name, model in models.iteritems():\n",
    "    print '\\n%s' % name\n",
    "    kfi = kf_over if (name=='Gradient Boosting') else kf\n",
    "    pipe = Pipeline([('trans',trans),('model',model)])\n",
    "    print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kfi, scoring=roc_scorer))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Table += Interesting Words\n",
    "\n",
    "The following table documents our results so far. The mean and median scores come from taking the averge of the ROC-AUC scores from 10 k-fold in the specified model.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Activity Features with Reweighted Classes</td>\n",
    "<td>0.5589</td>\n",
    "<td>0.5570</td>\n",
    "<td>0.0213</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Simple BOW, Titles + Bodies, Snowball Stem Tokenizer</td>\n",
    "<td>0.5615</td>\n",
    "<td>0.5604</td>\n",
    "<td>0.0243</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees BOW w/ L1 Feature Reduction Bodies</td>\n",
    "<td>0.5870</td>\n",
    "<td>0.5920</td>\n",
    "<td>0.0271</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Month, Hour</td>\n",
    "<td>0.5406</td>\n",
    "<td>0.5440</td>\n",
    "<td>0.0232</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Interesting Word Tags in Request</td>\n",
    "<td>0.5509</td>\n",
    "<td>0.5582</td>\n",
    "<td>0.0363</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part6\"></a>\n",
    "## 6. Request Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.tokenize.regexp import RegexpTokenizer\n",
    "from sklearn.feature_extraction import text as sklearn_text\n",
    "brown_words = np.unique(np.array(brown.words()))\n",
    "brown_words = np.unique(np.array([x.lower() for x in brown_words]))\n",
    "brown_word2tag = {word.lower(): tag for word, tag in brown.tagged_words()}\n",
    "brown_tags = set([tag for word, tag in brown.tagged_words()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DEFAULT_WORD2TAG = brown_word2tag\n",
    "DEFAULT_TAG_SET = brown_tags\n",
    "DEFAULT_WORD_SET = set(brown_words)\n",
    "DEFAULT_STOP_WORDS = set(['request'])\n",
    "DEFAULT_TOKENIZER = RegexpTokenizer(r'[\\s\\.\\,\\:\\-\\;\\(\\)\\[\\]\\{\\}\\!\\?]+',gaps=True)\n",
    "\n",
    "# This calcualtes how many of the words are in the Brown corpus,\n",
    "# the idea is that this may capture more well written requests\n",
    "class InCorpusTransformer(TransformerMixin):\n",
    "    def __init__(self, word_set=DEFAULT_WORD_SET, tokenizer=DEFAULT_TOKENIZER, stop_words=DEFAULT_STOP_WORDS, normalize=True):\n",
    "        self.word_set = word_set\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stop_words = stop_words\n",
    "        self.tokenizer = tokenizer\n",
    "        self.normalize = normalize\n",
    "    \n",
    "    def count_tokens(self, tokens):\n",
    "        if len(tokens) == 0:\n",
    "            return 2\n",
    "        else:\n",
    "            return sum(np.array([token.lower() in self.word_set for token in tokens]))/float(len(tokens))\n",
    "    \n",
    "    def tokenize_and_count(self, text):\n",
    "        tokens = [x.lower() for x in self.tokenizer.tokenize(text) if x.lower() not in self.stop_words]\n",
    "        return self.count_tokens(tokens)\n",
    "    \n",
    "    def process_vector(self, texts):\n",
    "        return np.array([[self.tokenize_and_count(text) for text in texts]]).T\n",
    "        \n",
    "    def transform(self, X, **transform_params):\n",
    "        if len(X.shape) == 1:\n",
    "            lens = lenArray(X)\n",
    "            if self.normalize:\n",
    "                return self.process_vector(X)/lens\n",
    "            else:\n",
    "                return self.process_vector(X)\n",
    "        else:\n",
    "            features = []\n",
    "            for col in range(X.shape[1]):\n",
    "                lens = lenArray(X[:,col])\n",
    "                if self.normalize:\n",
    "                    features.append(self.process_vector(X[:,col])/lens)\n",
    "                else:\n",
    "                    features.append(self.process_vector(X[:,col]))\n",
    "            return np.hstack(tuple(features))\n",
    "        \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        #do nothing\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'normalize':self.normalize}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature transformer calculates whether words in the request are also present in the Brown University Standard Corpus of Present Day American English. We noticed that \"well written\" requests tended to perform better, and thought that perhaps requests that used mroe \"standard english\" words may be perceived as more well written. Additionally, the Brown corpus tags words by part of speech, and we used this information to create another feautre set below. \n",
    "\n",
    "It's also worth noting that via analysis of our errors we noted that this feature overly favored long requests. This made us realize we should adjust by the length of the request which led to better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incorpus = Pipeline([('all_text', ExtractAllText()),('concat', ConcatStringTransformer()),('in',InCorpusTransformer())])\n",
    "incorpus_raw = Pipeline([('all_text', ExtractAllText()),('concat', ConcatStringTransformer()),('in',InCorpusTransformer(normalize=False))])\n",
    "etc = ExtraTreesClassifier(n_estimators = 200,\n",
    "                           max_depth = 4,\n",
    "                           min_samples_split=15,\n",
    "                           random_state=rseed,\n",
    "                           class_weight='auto')\n",
    "\n",
    "lsvc = Pipeline([('scale', StandardScaler()), ('clf', LinearSVC(class_weight='auto', random_state=rseed))])\n",
    "\n",
    "print 'LSVC on unnormalized counts'\n",
    "pipe = Pipeline([('incorpus', incorpus_raw), ('model', lsvc)])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "print 'LSVC on normalized counts'\n",
    "\n",
    "pipe = Pipeline([('incorpus', incorpus), ('model', lsvc)])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "print 'ETC on unnormalized counts'\n",
    "pipe = Pipeline([('incorpus', incorpus_raw), ('model', etc)])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "print 'ETC on normalized counts'\n",
    "\n",
    "pipe = Pipeline([('incoprus', incorpus), ('model', etc)])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Table += Spelling Mistakes\n",
    "\n",
    "The following table documents our results so far. The mean and median scores come from taking the averge of the ROC-AUC scores from 10 k-folds in the specified model.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Activity Features with Reweighted Classes</td>\n",
    "<td>0.5589</td>\n",
    "<td>0.5570</td>\n",
    "<td>0.0213</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Simple BOW, Titles + Bodies, Snowball Stem Tokenizer</td>\n",
    "<td>0.5615</td>\n",
    "<td>0.5604</td>\n",
    "<td>0.0243</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees BOW w/ L1 Feature Reduction Bodies</td>\n",
    "<td>0.5870</td>\n",
    "<td>0.5920</td>\n",
    "<td>0.0271</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Month, Hour</td>\n",
    "<td>0.5406</td>\n",
    "<td>0.5440</td>\n",
    "<td>0.0232</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Interesting Word Tags in Request</td>\n",
    "<td>0.5509</td>\n",
    "<td>0.5582</td>\n",
    "<td>0.0363</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Request Quality (LSVC)</td>\n",
    "<td>0.5706</td>\n",
    "<td>0.5800</td>\n",
    "<td>0.0227</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Request Quality (ETC)</td>\n",
    "<td>0.5639</td>\n",
    "<td>0.5695</td>\n",
    "<td>0.0248</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part7\"></a>\n",
    "## 7. Text Summary Features: Text Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Reusable class for text length:\n",
    "\n",
    "TITLE_COLUMN = np.where(all_train_df.columns == 'request_title')[0][0]\n",
    "BODY_COLUMN = np.where(all_train_df.columns == 'request_text_edit_aware')[0][0]\n",
    "\n",
    "class TextSummaryTransformer(TransformerMixin):\n",
    "    def __init__(self, title_col=TITLE_COLUMN, body_col=BODY_COLUMN, do_title=True, do_body=True):\n",
    "        self.do_title = do_title\n",
    "        self.do_body = do_body\n",
    "        self.title_col = title_col\n",
    "        self.body_col = body_col\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        do_title = self.do_title\n",
    "        do_body = self.do_body\n",
    "        title_col = self.title_col\n",
    "        body_col = self.body_col\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        if do_title:\n",
    "            title_unicode = X[:, title_col]\n",
    "            title_len = np.array([[len(x.encode('utf-8')) for x in title_unicode]]).T\n",
    "            features.append(title_len)\n",
    "            \n",
    "        if do_body:\n",
    "            body_unicode = X[:, body_col]\n",
    "            body_len = np.array([[len(x.encode('utf-8')) for x in body_unicode]]).T\n",
    "            features.append(body_len)\n",
    "        \n",
    "        return np.hstack(tuple(features))\n",
    "        \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        #do nothing\n",
    "        return self \n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
    "        return {}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features simply check how long the request title and body were, since respondents may be more or less likely to grant long eloquent requests or short concise requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators = 200,\n",
    "                           max_depth = 4,\n",
    "                           min_samples_split=15,\n",
    "                           random_state=rseed,\n",
    "                           class_weight='auto')\n",
    "\n",
    "lsvc = Pipeline([('scale', StandardScaler()), ('clf', LinearSVC(class_weight='auto', random_state=rseed))])\n",
    "\n",
    "\n",
    "print '\\nExtra Trees Classifier on title and body length'\n",
    "pipe = Pipeline([('text_summary', TextSummaryTransformer()), ('etc', etc)])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))\n",
    "\n",
    "print '\\Linear SVC on title and body length'\n",
    "pipe = Pipeline([('text_summary', TextSummaryTransformer()), ('lsvc', lsvc)])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Table += Text Summary Features\n",
    "\n",
    "The following table documents our results so far. The mean and median scores come from taking the averge of the ROC-AUC scores from 5 k-folds in the specified model.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Activity Features with Reweighted Classes</td>\n",
    "<td>0.5589</td>\n",
    "<td>0.5570</td>\n",
    "<td>0.0213</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Simple BOW, Titles + Bodies, Snowball Stem Tokenizer</td>\n",
    "<td>0.5615</td>\n",
    "<td>0.5604</td>\n",
    "<td>0.0243</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees BOW w/ L1 Feature Reduction Bodies</td>\n",
    "<td>0.5870</td>\n",
    "<td>0.5920</td>\n",
    "<td>0.0271</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Month, Hour</td>\n",
    "<td>0.5406</td>\n",
    "<td>0.5440</td>\n",
    "<td>0.0232</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Interesting Word Tags in Request</td>\n",
    "<td>0.5509</td>\n",
    "<td>0.5582</td>\n",
    "<td>0.0363</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Request Quality (LSVC)</td>\n",
    "<td>0.5706</td>\n",
    "<td>0.5800</td>\n",
    "<td>0.0227</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Request Quality (ETC)</td>\n",
    "<td>0.5639</td>\n",
    "<td>0.5695</td>\n",
    "<td>0.0248</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Title and Body Length</td>\n",
    "<td>0.5787</td>\n",
    "<td>0.5813</td>\n",
    "<td>0.0243</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part8\"></a>\n",
    "## 8. Location Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Collect location name metadata\n",
    "\n",
    "MANUAL_GEOS = [\n",
    "{'loc':'nyc', 'g1':'ny', 'g2':'us'},\n",
    "{'loc':'sf', 'g1':'ca', 'g2':'us'},\n",
    "{'loc':'uk', 'g1':'uk', 'g2':'non_us'},\n",
    "{'loc':'australia', 'g1':'aus', 'g2':'non_us'},\n",
    "{'loc':'canada', 'g1':'can', 'g2':'non_us'},\n",
    "{'loc':'ottawa', 'g1':'can', 'g2':'non_us'},\n",
    "{'loc':'toronto', 'g1':'can', 'g2':'non_us'},\n",
    "{'loc':'vancouver', 'g1':'can', 'g2':'non_us'},\n",
    "{'loc':'montreal', 'g1':'can', 'g2':'non_us'}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def make_geo(other_geos=MANUAL_GEOS, filter_loc=[]):\n",
    "\n",
    "    from bs4 import BeautifulSoup\n",
    "    from urllib import urlopen\n",
    "    import re\n",
    "    \n",
    "    ######################\n",
    "    # Scrape wikipedia list of us cities\n",
    "    \n",
    "    # TODO save local\n",
    "    webpage = urlopen('http://en.wikipedia.org/wiki/List_of_United_States_cities_by_population')\n",
    "    \n",
    "    # parse webpage to find the table\n",
    "    soup=BeautifulSoup(webpage, \"html.parser\")\n",
    "    table = soup.find('table', {'class' : 'wikitable sortable'})\n",
    "    \n",
    "    # stroe the first 200 US cities\n",
    "    us_cities = []\n",
    "    rows = table.findAll('tr')\n",
    "    for row in rows[1:200]:\n",
    "        cells = row.findAll('td')\n",
    "\n",
    "        output = []\n",
    "\n",
    "        for i, cell in enumerate(cells):\n",
    "            if i < 4:\n",
    "                text = cell.text.strip().lower()\n",
    "                if i == 0:\n",
    "                    text = int(text)\n",
    "                if i == 1 or i == 2:\n",
    "                    text = re.sub(r\"\\[.*\\]|'\",'',text)\n",
    "                if i == 3:\n",
    "                    text = int(re.sub(r',','',text))\n",
    "                output.append(text)\n",
    "        us_cities.append(output)\n",
    "\n",
    "    us_cities = pd.DataFrame(np.array(us_cities),columns=['rank','city','state','pop'])\n",
    "    \n",
    "    ###########################\n",
    "    # tuple list of state abbreviations\n",
    "    \n",
    "    state_abr_raw = [(\"Alabama\",\"AL\"),(\"Alaska\",\"AK\"),(\"Arizona\",\"AZ\"),\n",
    "                     (\"Arkansas\",\"AR\"),(\"California\",\"CA\"),(\"Colorado\",\"CO\"),\n",
    "                     (\"Connecticut\",\"CT\"),(\"Delaware\",\"DE\"),(\"District of Columbia\",\"DC\"),\n",
    "                     (\"Florida\",\"FL\"),(\"Georgia\",\"GA\"),(\"Hawaii\",\"HI\"),\n",
    "                     (\"Idaho\",\"ID\"),(\"Illinois\",\"IL\"),(\"Indiana\",\"IN\"),\n",
    "                     (\"Iowa\",\"IA\"),(\"Kansas\",\"KS\"),(\"Kentucky\",\"KY\"),\n",
    "                     (\"Louisiana\",\"LA\"),(\"Maine\",\"ME\"),(\"Montana\",\"MT\"),\n",
    "                     (\"Nebraska\",\"NE\"),(\"Nevada\",\"NV\"),(\"New Hampshire\",\"NH\"),\n",
    "                     (\"New Jersey\",\"NJ\"),(\"New Mexico\",\"NM\"),(\"New York\",\"NY\"),\n",
    "                     (\"North Carolina\",\"NC\"),(\"North Dakota\",\"ND\"),(\"Ohio\",\"OH\"),\n",
    "                     (\"Oklahoma\",\"OK\"),(\"Oregon\",\"OR\"),(\"Maryland\",\"MD\"),\n",
    "                     (\"Massachusetts\",\"MA\"),(\"Michigan\",\"MI\"),(\"Minnesota\",\"MN\"),\n",
    "                     (\"Mississippi\",\"MS\"),(\"Missouri\",\"MO\"),(\"Pennsylvania\",\"PA\"),\n",
    "                     (\"Rhode Island\",\"RI\"),(\"South Carolina\",\"SC\"),(\"South Dakota\",\"SD\"),\n",
    "                     (\"Tennessee\",\"TN\"),(\"Texas\",\"TX\"),(\"Utah\",\"UT\"),\n",
    "                     (\"Vermont\",\"VT\"),(\"Virginia\",\"VA\"),(\"Washington\",\"WA\"),\n",
    "                     (\"West Virginia\",\"WV\"),(\"Wisconsin\",\"WI\"),(\"Wyoming\",\"WY\")]\n",
    "    \n",
    "    ############################\n",
    "    # manupulate state abreviations\n",
    "    state_abr = []\n",
    "    for st, abr in state_abr_raw:\n",
    "        state_abr.append([st.lower(), abr.lower()])\n",
    "    state_abr = pd.DataFrame(np.array(state_abr), columns = ['state','abr'])\n",
    "    \n",
    "    #############################\n",
    "    # make US Geos\n",
    "    us_city_state = pd.merge(us_cities,state_abr)\n",
    "    \n",
    "    # US geos\n",
    "    usgeo = us_city_state.loc[:,['city','abr']]\n",
    "    usgeo.columns = ['loc','g1']\n",
    "    usgeo = pd.concat([usgeo,pd.DataFrame({'loc':state_abr.abr,'g1':state_abr.abr})])\n",
    "    usgeo = pd.concat([usgeo,pd.DataFrame({'loc':state_abr.state,'g1':state_abr.abr})])\n",
    "    usgeo['g2'] = 'us'\n",
    "    \n",
    "    \n",
    "    geo = pd.concat([usgeo, pd.DataFrame(other_geos)])\n",
    "    \n",
    "    # get rid of auto generated locations with confusiong names\n",
    "    #geo = geo[[not x in filter_loc for x in geo['loc']]]\n",
    "    \n",
    "    return geo\n",
    "\n",
    "geo = make_geo()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reusable class for finding location names and aggregating them for different metadata\n",
    "\n",
    "DEFAULT_TOKENIZER = RegexpTokenizer(r'[\\s\\.\\,\\:\\-\\;\\(\\)\\[\\]\\{\\}\\!\\?]+',gaps=True)\n",
    "FILTER_DEFAULT = ['in', 'hi', 'me', 'ok', 'HI', 'OK', 'or']\n",
    "DEFAULT_GEO = geo\n",
    "\n",
    "class GeoTransformer(TransformerMixin):\n",
    "    \n",
    "    def __init__(self, geo=DEFAULT_GEO, level=2, tokenizer=DEFAULT_TOKENIZER, stop_words=FILTER_DEFAULT, total_only=True, normalize=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stop_words = stop_words\n",
    "        self.geo = geo\n",
    "        self.level = level\n",
    "        self.normalize = normalize\n",
    "        self.total_only = total_only\n",
    "        \n",
    "    def find_words(self, words, texts, g1=None, g2=None, lower=True):\n",
    "        word_dict = {}\n",
    "        do_g1 = not g1 is None\n",
    "        do_g2 = not g2 is None\n",
    "        \n",
    "        if do_g1:\n",
    "            g1_dict = {}\n",
    "            \n",
    "        if do_g2:\n",
    "            g2_dict = {}\n",
    "        \n",
    "        #token_list = [[x.lower() for x in self.tokenizer.tokenize(text) if x not in self.stop_words] for text in texts]\n",
    "    \n",
    "        i = 0\n",
    "        for word in words:\n",
    "            if not word in self.stop_words:\n",
    "                regex = re.compile('\\\\b('+word+')\\\\b')\n",
    "                has_word = np.array([(1 if regex.search(text.lower()) else 0) for text in texts])\n",
    "                word_dict[word] = has_word\n",
    "                if do_g1:\n",
    "                    g1i = g1.iloc[i]\n",
    "                    if g1i in g1_dict:\n",
    "                        g1_dict[g1i] += has_word\n",
    "                    else:\n",
    "                        g1_dict[g1i] = has_word\n",
    "                        \n",
    "                if do_g2:\n",
    "                    g2i = g2.iloc[i]\n",
    "                    if g2i in g2_dict:\n",
    "                        g2_dict[g2i] += has_word\n",
    "                    else:\n",
    "                        g2_dict[g2i] = has_word\n",
    "                        \n",
    "            i += 1\n",
    "\n",
    "        return (word_dict, g1_dict, g2_dict)\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        geo = self.geo\n",
    "        find_words = self.find_words\n",
    "        level = self.level\n",
    "        normalize = self.normalize\n",
    "        \n",
    "        words = geo['loc']\n",
    "        g1 = geo['g1']\n",
    "        g2 = geo['g2']\n",
    "        \n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        \n",
    "        if len(X.shape) > 1:\n",
    "            cols = X.shape[1]\n",
    "            for i in cols:\n",
    "                locs, g1s, g2s = find_words(words, X[:,i], g1s, g2s)\n",
    "                \n",
    "                if level == 0:\n",
    "                    df = pd.DataFrame(locs)\n",
    "                elif level == 1:\n",
    "                    df = pd.DataFrame(g1s)\n",
    "                elif level > 1:\n",
    "                    df = pd.DataFrame(g2s)\n",
    "                    \n",
    "                #df = pd.DataFrame(locss)\n",
    "                features.append(df.values)\n",
    "        else:\n",
    "            lens = lenArray(X)\n",
    "            \n",
    "            locs, g1s, g2s = find_words(words, X, g1, g2)\n",
    "            \n",
    "            if level == 0:\n",
    "                df = pd.DataFrame(locs)\n",
    "            elif level == 1:\n",
    "                df = pd.DataFrame(g1s)\n",
    "            elif level > 1:\n",
    "                df = pd.DataFrame(g2s)\n",
    "            \n",
    "            #df = pd.DataFrame(locss)\n",
    "            if normalize:\n",
    "                features.append(df.values/lens)\n",
    "            else:\n",
    "                features.append(df.values)\n",
    "            #print df.values/lens\n",
    "        \n",
    "        ret_array = np.hstack(tuple(features))\n",
    "        \n",
    "        total = np.reshape(np.sum(ret_array,1),(ret_array.shape[0],1))\n",
    "        \n",
    "        if self.total_only:\n",
    "            self.feature_names_ = np.array([u'Total'])\n",
    "            \n",
    "            return total\n",
    "        else:\n",
    "            self.feature_names_ = np.hstack((df.columns.values,u'Total'))\n",
    "\n",
    "            return np.hstack((ret_array, total))\n",
    "\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        #do nothing\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
    "        return {'level':self.level, 'normalize':self.normalize}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking through our errors, we noticed that we were missing alot of successful requests that included location names. We also noticed on the Reddit page that you have to include a location for your request to be granted (duh). So we scraped a list of US city names and their associated states. We also created a list of us states and their abbreviations. Finally, we added a few locations of our own. This transformer, looks for matches of these location names and aggregates them, usually based on state (based on country for international locations)\n",
    "\n",
    "\n",
    "UNFORTUNATELY, it didn't actually add much value... but thought we'd include it here anyway, cuz it was a lot of work and could be interesting for others to use in other problems or improve here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_trans = GeoTransformer(geo, level = 1, total_only = False, normalize = False)\n",
    "geo_title = geo_trans.transform(ExtractTitle().transform(all_train_df.values))\n",
    "geo_body = geo_trans.transform(ExtractBody().transform(all_train_df.values))\n",
    "\n",
    "\n",
    "print 'Individual occurences in title:'\n",
    "print zip(geo_trans.feature_names_, np.sum(geo_title,0))\n",
    "\n",
    "\n",
    "print 'Individual occurences in body:'\n",
    "print zip(geo_trans.feature_names_, np.sum(geo_body,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators = 200,\n",
    "                           max_depth = 4,\n",
    "                           min_samples_split=15,\n",
    "                           random_state = rseed,\n",
    "                           class_weight='auto')\n",
    "\n",
    "level = 1\n",
    "\n",
    "title = Pipeline([('text',ExtractTitle()),('geo',GeoTransformer(geo, level=level))])\n",
    "body = Pipeline([('text',ExtractBody()),('geo',GeoTransformer(geo, level=level))])\n",
    "all_text = Pipeline([('text',ExtractAllText()),('combine',ConcatStringTransformer()),('geo',GeoTransformer(geo,level=level))])\n",
    "\n",
    "pipe = Pipeline([('features',body),('model',etc)])\n",
    "\n",
    "print 'Body:'\n",
    "pipe = Pipeline([('features',body),('model',etc)])\n",
    "scores = cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer)\n",
    "print_scores(scores)\n",
    "\n",
    "print 'Title:'\n",
    "pipe = Pipeline([('features',title),('model',etc)])\n",
    "scores = cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer)\n",
    "print_scores(scores)\n",
    "\n",
    "print 'On Concat Title/Body:'\n",
    "pipe = Pipeline([('features',all_text),('model',etc)])\n",
    "scores = cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer)\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Table += Text Summary Features\n",
    "\n",
    "The following table documents our results so far. The mean and median scores come from taking the averge of the ROC-AUC scores from 5 k-folds in the specified model.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Activity Features with Reweighted Classes</td>\n",
    "<td>0.5589</td>\n",
    "<td>0.5570</td>\n",
    "<td>0.0213</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Simple BOW, Titles + Bodies, Snowball Stem Tokenizer</td>\n",
    "<td>0.5615</td>\n",
    "<td>0.5604</td>\n",
    "<td>0.0243</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees BOW w/ L1 Feature Reduction Bodies</td>\n",
    "<td>0.5870</td>\n",
    "<td>0.5920</td>\n",
    "<td>0.0271</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Month, Hour</td>\n",
    "<td>0.5406</td>\n",
    "<td>0.5440</td>\n",
    "<td>0.0232</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Interesting Word Tags in Request</td>\n",
    "<td>0.5509</td>\n",
    "<td>0.5582</td>\n",
    "<td>0.0363</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Request Quality (LSVC)</td>\n",
    "<td>0.5706</td>\n",
    "<td>0.5800</td>\n",
    "<td>0.0227</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Request Quality (ETC)</td>\n",
    "<td>0.5639</td>\n",
    "<td>0.5695</td>\n",
    "<td>0.0248</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Title and Body Length</td>\n",
    "<td>0.5787</td>\n",
    "<td>0.5813</td>\n",
    "<td>0.0243</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees of Location Features on Title and Body Length</td>\n",
    "<td>0.5207</td>\n",
    "<td>0.5157</td>\n",
    "<td>0.0252</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part9\"></a>\n",
    "## 9. Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# For Part of Speech Tagging\n",
    "class Word2TagTransformer(TransformerMixin):\n",
    "    def __init__(self, tag_set=DEFAULT_TAG_SET, word_set=DEFAULT_WORD_SET, word2tag=DEFAULT_WORD2TAG, tokenizer=DEFAULT_TOKENIZER, stop_words=DEFAULT_STOP_WORDS):\n",
    "        self.tag_set = tag_set\n",
    "        self.word_set = word_set\n",
    "        self.word2tag = word2tag\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stop_words = stop_words\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tags_dict = {tag: 0 for tag in tag_set}\n",
    "    \n",
    "    def tag_tokens(self, tokens):\n",
    "        tag_tokens = []\n",
    "        \n",
    "        for token in tokens:\n",
    "            token = token.lower()\n",
    "            if (token in self.word_set) and (token not in self.stop_words):\n",
    "                tag_tokens.append(self.word2tag[token])\n",
    "        \n",
    "        return ' '.join(tag_tokens)\n",
    "        \n",
    "    \n",
    "    def tokenize_and_tag(self, text):\n",
    "        tokens = [x.lower() for x in self.tokenizer.tokenize(text) if x.lower() not in self.stop_words]\n",
    "        return self.tag_tokens(tokens)\n",
    "    \n",
    "    def process_vector(self, texts):\n",
    "        return np.array([[self.tokenize_and_tag(text) for text in texts]]).T\n",
    "        \n",
    "    def transform(self, X, **transform_params):\n",
    "        if len(X.shape) == 1:\n",
    "            return self.process_vector(X).flatten()\n",
    "        else:\n",
    "            features = []\n",
    "            for col in range(X.shape[1]):\n",
    "                features.append(self.process_vector(X[:,col]))\n",
    "            return np.hstack(tuple(features))\n",
    "        \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        #do nothing\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of feature transformers replaces words with their parts of speech as tagged in the Brown corpus. I then counts the term frequency on the parts of speech tags. Our thinking was again that higher quality or lower quality requests may use different semantic constructs and that this analysis would extract that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tv_space = TfidfVectorizer(ngram_range=(1,1),lowercase=True, token_pattern=u'[^\\s-]')\n",
    "all_text = Pipeline([('all_text', ExtractAllText()),('concat', ConcatStringTransformer())])\n",
    "etc = ExtraTreesClassifier(n_estimators = 200,\n",
    "                           max_depth = 4,\n",
    "                           min_samples_split=15,\n",
    "                           random_state=rseed,\n",
    "                           class_weight='auto')\n",
    "\n",
    "\n",
    "lsvc = LinearSVC(class_weight='auto', random_state=rseed)\n",
    "\n",
    "pipe_nol1 = Pipeline([\n",
    "    ('text',all_text),\n",
    "    ('word2tag', Word2TagTransformer()),\n",
    "    ('tv',tv_space)\n",
    "])\n",
    "\n",
    "print '\\nLinear SVC on Brown corpus word tags:'\n",
    "pipe = Pipeline([('process', pipe_nol1),('model',lsvc)])\n",
    "scores = cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer, verbose=1)\n",
    "print_scores(scores)\n",
    "\n",
    "print '\\nExtra Trees on Brown corpus word tags:'\n",
    "pipe = Pipeline([('process', pipe_nol1),('model',etc)])\n",
    "scores = cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer, verbose=1)\n",
    "print_scores(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part10\"></a>\n",
    "## 10 Subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reusable class that transforms the list of subreddits for each user in to space seperated string for use by \n",
    "# the tfidf vectorizer\n",
    "SUBREDDITS_COLUMN = np.where(all_train_df.columns == 'requester_subreddits_at_request')[0][0]\n",
    "\n",
    "class SubredditTransformer(TransformerMixin):\n",
    "   \n",
    "    def __init__(self, column = SUBREDDITS_COLUMN):\n",
    "        self.column = column\n",
    "   \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        return self\n",
    "   \n",
    "    def transform(self, X, **transform_params):\n",
    "        return np.array([' '.join(x) for x in X[:,self.column]])\n",
    "   \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature creator makes a term frequency matrix out of the list of subreddits that each requesting user contributes to. We decided to use a tree ensemble to test this method, because there may be interactive elements (presence of one subreddit and another). We also use L1 feature regularization as described in the text section above to reduce the feature set. We chose C such that we didn't get too many features (only 20) but didn't lose much explanatory power vs using lots more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators=200,\n",
    "                            max_depth=4,\n",
    "                            min_samples_split=15,\n",
    "                            random_state = rseed,\n",
    "                            class_weight='auto')\n",
    "l1 = LinearWeightFeatureThreshold(C=.15)\n",
    "tv_space = TfidfVectorizer(token_pattern = u'[^\\s]+', min_df=10)\n",
    "pipe = Pipeline([('sub',SubredditTransformer()), ('tv', tv_space), ('l1', l1), ('model',etc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer, verbose=1)\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Table += Subreddits + Parts of Speech\n",
    "\n",
    "The following table documents our results so far. The mean and median scores come from taking the averge of the ROC-AUC scores from 10 k-folds in the specified model.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Activity Features with Reweighted Classes</td>\n",
    "<td>0.5589</td>\n",
    "<td>0.5570</td>\n",
    "<td>0.0213</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Simple BOW, Titles + Bodies, Snowball Stem Tokenizer</td>\n",
    "<td>0.5615</td>\n",
    "<td>0.5604</td>\n",
    "<td>0.0243</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees BOW w/ L1 Feature Reduction Bodies</td>\n",
    "<td>0.5870</td>\n",
    "<td>0.5920</td>\n",
    "<td>0.0271</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Month, Hour</td>\n",
    "<td>0.5406</td>\n",
    "<td>0.5440</td>\n",
    "<td>0.0232</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Interesting Word Tags in Request</td>\n",
    "<td>0.5509</td>\n",
    "<td>0.5582</td>\n",
    "<td>0.0363</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Request Quality (LSVC)</td>\n",
    "<td>0.5706</td>\n",
    "<td>0.5800</td>\n",
    "<td>0.0227</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Request Quality (ETC)</td>\n",
    "<td>0.5639</td>\n",
    "<td>0.5695</td>\n",
    "<td>0.0248</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Title and Body Length</td>\n",
    "<td>0.5787</td>\n",
    "<td>0.5813</td>\n",
    "<td>0.0243</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees of Location Features on Title and Body Length</td>\n",
    "<td>0.5207</td>\n",
    "<td>0.5157</td>\n",
    "<td>0.0252</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees of Parts of Speech</td>\n",
    "<td>0.5530</td>\n",
    "<td>0.5513</td>\n",
    "<td>0.0167</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees of Subreddits</td>\n",
    "<td>0.5586</td>\n",
    "<td>0.5581</td>\n",
    "<td>0.0262</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part11\"></a>\n",
    "## 11. Final, Composite Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We took two approaches to combining these features sets.\n",
    "In one, we checked which feature sets were the best and started with those. We then iteratively add additional feature sets to see whether or not they improve performance. If they don't add anything or subtract value, we remove them and keep going.\n",
    "In the other, we don't choose at all and leave it to the model to decide.\n",
    "\n",
    "Secondly, we try three different kinds of ensembled decision trees that get roughly similar results. Decision trees (a bunch of consecutive binary splits of the data based on variable values) can be a useful way to explore models where features my be nonlinear. Repeating a previous example, for the time features, hour 23.5 (late at night) and 0.5 (so early in the morning it's still late at night) may be treated similarly by a linear model, but a decision tree, can create a couple splites and capture it easily (hour > 23 and hour < 1).\n",
    "\n",
    "The \"ensemble\" part of \"tree ensemble\" means we constructing a ton of different decision trees, then average the prediction of each tree to inform our final prediction. This reduces the overfitting that can occur in a single decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feats = {}\n",
    "all_feats={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "lsvc = LinearSVC(class_weight='auto', random_state=rseed)\n",
    "etc = ExtraTreesClassifier(n_estimators = 200,\n",
    "                           max_depth = 4,\n",
    "                           min_samples_split=15,\n",
    "                           random_state=rseed,\n",
    "                           class_weight='auto')\n",
    "rfc = RandomForestClassifier(n_estimators = 200,\n",
    "                           max_depth = 4,\n",
    "                           min_samples_split=15,\n",
    "                           random_state=rseed,\n",
    "                           class_weight='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with Extra Trees on BOW w/ L1 Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Try ExtraTreesClassifier for the BOW models:\n",
    "\n",
    "l1_bow = LinearWeightFeatureThreshold(C=0.15)\n",
    "tv_bow = TfidfVectorizer(tokenizer=SnowballStemTokenizer())\n",
    "\n",
    "all_feats['bow_l1'] = Pipeline([('extract', ExtractBody()), ('tv',tv_bow), ('features',l1_bow)])\n",
    "feats['bow_l1'] = all_feats['bow_l1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('featues', FeatureUnion(feats.items())),('model',etc)])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Extra Trees BOW w/ L1 Feature Reduction Bodies</td>\n",
    "<td>0.5870</td>\n",
    "<td>0.5920</td>\n",
    "<td>0.0271</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Tile and Body Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_feats['length'] = TextSummaryTransformer()\n",
    "feats['length'] = all_feats['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('featues', FeatureUnion(feats.items())),('model',etc)])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del feats['length']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Prevailing Model</td>\n",
    "<td>0.5870</td>\n",
    "<td>0.5920</td>\n",
    "<td>0.0271</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>+Body & Title Length (NO ADDITION)</td>\n",
    "<td>0.5864</td>\n",
    "<td>0.5865</td>\n",
    "<td>0.0211</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try adding request quality to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incorpus = Pipeline([('all_text', ExtractAllText()),('concat', ConcatStringTransformer()),('in',InCorpusTransformer())])\n",
    "all_feats['incorpus']=incorpus\n",
    "feats['incorpus']=incorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('featues', FeatureUnion(feats.items())),('model',etc)])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#del feats['incorpus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Prevailing Model</td>\n",
    "<td>0.5870</td>\n",
    "<td>0.5920</td>\n",
    "<td>0.0271</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>+Request Quality (words from brown corpus)</td>\n",
    "<td>0.5903</td>\n",
    "<td>0.5992</td>\n",
    "<td>0.0274</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add subreddit analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1 = LinearWeightFeatureThreshold(C=.15)\n",
    "tv_space = TfidfVectorizer(token_pattern = u'[^\\s]+', min_df=10)\n",
    "\n",
    "sub = Pipeline([('sub',SubredditTransformer()), ('tv', tv_space), ('l1', l1)])\n",
    "feats['sub'] = sub\n",
    "all_feats['sub'] = sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('featues', FeatureUnion(feats.items())),('model',etc)])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It didn't help at all so will leave it out for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del feats['sub']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Prevailing Model</td>\n",
    "<td>0.5903</td>\n",
    "<td>0.5992</td>\n",
    "<td>0.0274</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>+Subreddit Analysis</td>\n",
    "<td>0.5913</td>\n",
    "<td>0.5932</td>\n",
    "<td>0.0309</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add activity features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acts = ExtractActivities()\n",
    "all_feats['activities'] = acts\n",
    "feats['activities'] = acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('featues', FeatureUnion(feats.items())),('model',etc)])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#del feats['activities']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Prevailing Model</td>\n",
    "<td>0.5903</td>\n",
    "<td>0.5992</td>\n",
    "<td>0.0273</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>+Activities</td>\n",
    "<td>0.5964</td>\n",
    "<td>0.5882</td>\n",
    "<td>0.0227</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add parts of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tv_space = TfidfVectorizer(ngram_range=(1,1),lowercase=True, token_pattern=u'[^\\s-]')\n",
    "all_text = Pipeline([('all_text', ExtractAllText()),('concat', ConcatStringTransformer())])\n",
    "\n",
    "pos_tags = Pipeline([\n",
    "    ('text',all_text),\n",
    "    ('word2tag', Word2TagTransformer()),\n",
    "    ('tv',tv_space),\n",
    "    ('desparse', DesparseTransformer())\n",
    "])\n",
    "\n",
    "all_feats['pos_tags'] = pos_tags\n",
    "feats['pos_tags'] = pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('featues', FeatureUnion(feats.items())),('model',etc)])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#del feats['pos_tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Prevailing Model</td>\n",
    "<td>0.5964</td>\n",
    "<td>0.5882</td>\n",
    "<td>0.0227</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>+Part of Speech Tags from Brown Corpus</td>\n",
    "<td>0.6024</td>\n",
    "<td>0.6116</td>\n",
    "<td>0.0198</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting word tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interesting = InterestingWordsTransformer(do_words=False)\n",
    "all_feats['interesting'] = interesting\n",
    "feats['interesting'] = interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('features', FeatureUnion(feats.items())),('model',etc)])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse, toss it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del feats['interesting']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Prevailing Model</td>\n",
    "<td>0.6024</td>\n",
    "<td>0.6116</td>\n",
    "<td>0.0198</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>+InterestingWords</td>\n",
    "<td>0.5958</td>\n",
    "<td>0.5916</td>\n",
    "<td>0.0147</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try adding time featues (month and hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times = TimeTransformer(do_day=False, do_dow=False, do_hour=True,do_minute=False,do_second=False,do_month=True)\n",
    "feats['times'] = times\n",
    "all_feats['times'] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('features', FeatureUnion(feats.items())),('model',etc)])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del feats['times']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Prevailing Model</td>\n",
    "<td>0.6024</td>\n",
    "<td>0.6116</td>\n",
    "<td>0.0198</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>+Times</td>\n",
    "<td>0.5981</td>\n",
    "<td>0.6056</td>\n",
    "<td>0.0225</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try adding subreddit features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1 = LinearWeightFeatureThreshold(C=.15)\n",
    "tv_space = TfidfVectorizer(token_pattern = u'[^\\s]+', min_df=10)\n",
    "\n",
    "sub = Pipeline([('sub',SubredditTransformer()), ('tv', tv_space), ('l1', l1)])\n",
    "feats['sub'] = sub\n",
    "all_feats['sub'] = sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('features', FeatureUnion(feats.items())),('model',etc)])\n",
    "print_scores(cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse, toss it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del feats['sub']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Prevailing Model</td>\n",
    "<td>0.6024</td>\n",
    "<td>0.6116</td>\n",
    "<td>0.0198</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>+Subreddit</td>\n",
    "<td>0.6009</td>\n",
    "<td>0.6079</td>\n",
    "<td>0.0280</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try all features with Extra Trees regularization then RandomForest prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest w/ All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('featues', FeatureUnion(all_feats.items())),('model',rfc)])\n",
    "rfc_all = cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer)\n",
    "print_scores(rfc_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Trees Classifier With All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('featues', FeatureUnion(all_feats.items())),('model',etc)])\n",
    "etc_all = cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf, scoring=roc_scorer)\n",
    "print_scores(etc_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting with All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators = 200,\n",
    "                            learning_rate=0.01,\n",
    "                           max_depth = 3,\n",
    "                           min_samples_split=10,\n",
    "                           random_state = rseed)\n",
    "pipe = Pipeline([('featues', FeatureUnion(all_feats.items())),('model',gbc)])\n",
    "# note we use the oversampled k fold kf_over\n",
    "gbc = cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf_over, scoring=roc_scorer)\n",
    "print_scores(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Aggregated Models\n",
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Best From Manual Stepwise Selection</td>\n",
    "<td>0.6024</td>\n",
    "<td>0.6116</td>\n",
    "<td>0.0198</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>All Features Gradient Boosting</td>\n",
    "<td>0.6114</td>\n",
    "<td>0.6070</td>\n",
    "<td>0.0325</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>All Features Extra Trees</td>\n",
    "<td>0.6035</td>\n",
    "<td>0.6052</td>\n",
    "<td>0.0255</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>All Features Random Forests</td>\n",
    "<td>0.6093</td>\n",
    "<td>0.6026</td>\n",
    "<td>0.0295</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "## Feature Models\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Method</th>\n",
    "<th>Mean ROC-AUC</th>\n",
    "<th>Median ROC-AUC</th>\n",
    "<th>Standard Deviation</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>Activity Features with Reweighted Classes</td>\n",
    "<td>0.5589</td>\n",
    "<td>0.5570</td>\n",
    "<td>0.0213</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Simple BOW, Titles + Bodies, Snowball Stem Tokenizer</td>\n",
    "<td>0.5615</td>\n",
    "<td>0.5604</td>\n",
    "<td>0.0243</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees BOW w/ L1 Feature Reduction Bodies</td>\n",
    "<td>0.5870</td>\n",
    "<td>0.5920</td>\n",
    "<td>0.0271</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Month, Hour</td>\n",
    "<td>0.5406</td>\n",
    "<td>0.5440</td>\n",
    "<td>0.0232</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Interesting Word Tags in Request</td>\n",
    "<td>0.5509</td>\n",
    "<td>0.5582</td>\n",
    "<td>0.0363</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Request Quality (LSVC)</td>\n",
    "<td>0.5706</td>\n",
    "<td>0.5800</td>\n",
    "<td>0.0227</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Request Quality (ETC)</td>\n",
    "<td>0.5639</td>\n",
    "<td>0.5695</td>\n",
    "<td>0.0248</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees on Title and Body Length</td>\n",
    "<td>0.5787</td>\n",
    "<td>0.5813</td>\n",
    "<td>0.0243</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees of Location Features on Title and Body Length</td>\n",
    "<td>0.5207</td>\n",
    "<td>0.5157</td>\n",
    "<td>0.0252</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees of Parts of Speech</td>\n",
    "<td>0.5530</td>\n",
    "<td>0.5513</td>\n",
    "<td>0.0167</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Extra Trees of Subreddits</td>\n",
    "<td>0.5586</td>\n",
    "<td>0.5581</td>\n",
    "<td>0.0262</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "<a href=\"#top\">Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part12\"></a>\n",
    "## 12. Notes On Error Analysis\n",
    "\n",
    "We built tools for error analysis and a few of the features above came out of that analysis.\n",
    "For example, we noticed that the intresting words and incorpus counting features massively preferred long requests. This led to us dividing the counts by the length of requests, sort if in the fashion of TFIDF calculations, which led to better results for those features.\n",
    "\n",
    "We also noded that a lot of the succesful requests we failed to identify had location names in them and looking on the Reddit group noticed that location was a requirement for fulfillment (which, logistically, is obvious in hindsight). This inpsired us to create our geographic word identificaiton feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tv = TfidfVectorizer(tokenizer=SnowballStemTokenizer())\n",
    "l1 = LinearWeightFeatureThreshold(C=0.3)\n",
    "\n",
    "etc = ExtraTreesClassifier(n_estimators = 200,\n",
    "                           max_depth = 4,\n",
    "                           min_samples_split=15,\n",
    "                           random_state=rseed,\n",
    "                           class_weight='auto')\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('body', Pipeline([('extract', ExtractBody()),\n",
    "         ('tv',tv),\n",
    "         ('features',l1)\n",
    "         ])),\n",
    "    ('model', etc)\n",
    "])  \n",
    "                    \n",
    "\n",
    "# Number of errors to examine per fold. Keep the number negative to find the biggest error cases.\n",
    "# Keep in mind that this will print 10x this many error cases.\n",
    "\n",
    "TITLE_COLUMN = np.where(all_train_df.columns == 'request_title')[0][0]\n",
    "BODY_COLUMN = np.where(all_train_df.columns == 'request_text_edit_aware')[0][0]\n",
    "\n",
    "\n",
    "num_errors_per_fold = -1\n",
    "\n",
    "check_kf = kf\n",
    "\n",
    "for train_index, test_index in check_kf:\n",
    "    X_train, X_test = all_train_df.values[train_index], all_train_df.values[test_index]\n",
    "    y_train, y_test = all_train_labels[train_index], all_train_labels[test_index]\n",
    "    \n",
    "    print X_train.shape\n",
    "    print X_test.shape\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "    cl_probs = pipe.predict_proba(X_test)\n",
    "\n",
    "    # Loop through this fold of test data and determine the R ratio for each one:\n",
    "    ratios = []\n",
    "    for i in range(0, cl_probs.shape[0]):\n",
    "        ratios.append(cl_probs[i].max() / cl_probs[i][y_test[i]])\n",
    "\n",
    "    # Find the 3 largest ratios and print them as error cases to examine:\n",
    "    ratios = np.asarray(ratios)\n",
    "    heavy_ratios = ratios.argsort()[num_errors_per_fold:][::-1]\n",
    "    for r in heavy_ratios:\n",
    "        print \"== We guessed %s for this, but it was actually %s. ==\" % (np.argmax(cl_probs[r]),\n",
    "                                                                         y_test[r])\n",
    "        print \"\\n\", X_test[r, TITLE_COLUMN]\n",
    "        print \"\\n\", X_test[r, BODY_COLUMN]\n",
    "        print \"\\n==========\\n\"\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part13\"></a>\n",
    "## 13. Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Thinker\n",
    "\n",
    "We used this function to easily explore our text and generate ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TheThinker(n):\n",
    "    bodies = ExtractBody().transform(all_train_df.values)\n",
    "    titles = ExtractTitle().transform(all_train_df.values)\n",
    "    username = ExtractUser().transform(all_train_df.values)\n",
    "    y = all_train_labels\n",
    "\n",
    "    choices = np.random.choice(np.arange(n_all),n)\n",
    "    for i in choices:\n",
    "        print '###########################'\n",
    "        if y[i]:\n",
    "            print 'SUCCESS'\n",
    "        else:\n",
    "            print 'FAILURE'\n",
    "\n",
    "        print 'User:', username[i]\n",
    "\n",
    "        print 'Title:'\n",
    "        print titles[i]\n",
    "\n",
    "        print 'Body:'\n",
    "        print bodies[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TheThinker(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Theory\n",
    "\n",
    "We used this transformer to create simple models that look for the occurence of strings in text. This was useful for testing hunches about significance when exploring our data set and doing error analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CheckWordsTransformer(TransformerMixin):\n",
    "    def __init__(self, words=[]):\n",
    "        self.words = words\n",
    "        \n",
    "    def find_words(self, words, text, lower=True):\n",
    "        word_dict = {}\n",
    "\n",
    "        for word in words:\n",
    "            if lower:\n",
    "                has_word = np.array([(1 if word in t.lower() else 0) for t in text])\n",
    "            else:\n",
    "                has_word = np.array([(1 if word in t else 0) for t in text])\n",
    "            word_dict[word] = has_word\n",
    "\n",
    "        return word_dict\n",
    "    \n",
    "    # manually create keywords with categories\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        words = self.words\n",
    "        find_words = self.find_words\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        if len(X.shape) > 1:\n",
    "            cols = X.shape[1]\n",
    "            for i in cols:\n",
    "                lens = lenArray(X[:,i])\n",
    "                features.append(pd.DataFrame(find_words(words, X[:,i])).values/lens)\n",
    "        else:\n",
    "            lens = lenArray(X)\n",
    "            features.append(pd.DataFrame(find_words(words, X)).values/lens)\n",
    "            \n",
    "        return np.hstack(tuple(features))\n",
    "    \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        #do nothing\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
    "        return {'words': self.words}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the string 'thank' is pretty explanatory... is it really a magic word?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strings = ['thank']\n",
    "pipe = Pipeline([('text',all_text),('strings',CheckWordsTransformer(words=strings)),('model',etc)])\n",
    "strings_cv = cross_val_score(pipe, all_train_df.values, all_train_labels, cv=kf_over, scoring=roc_scorer)\n",
    "print_scores(strings_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

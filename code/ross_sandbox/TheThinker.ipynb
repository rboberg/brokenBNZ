{
 "metadata": {
  "name": "",
  "signature": "sha256:3db4d8348af28ba2eaf604f00d945a4ba58830e121e740f2c27a9e33f09c5a0e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import json\n",
      "import csv\n",
      "import numpy as np\n",
      "import random as rand\n",
      "import pandas as pd\n",
      "import scipy as scipy\n",
      "import datetime as dt\n",
      "import time\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import roc_auc_score\n",
      "from sklearn.cross_validation import KFold\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.pipeline import FeatureUnion\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.mixture import GMM\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.metrics import make_scorer\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.decomposition import RandomizedPCA\n",
      "\n",
      "import gensim\n",
      "\n",
      "from sklearn.base import TransformerMixin\n",
      "from sklearn.base import BaseEstimator\n",
      "from sklearn.grid_search import GridSearchCV"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#useful for text processing\n",
      "from nltk import word_tokenize\n",
      "from nltk.stem import WordNetLemmatizer\n",
      "from nltk.stem.porter import PorterStemmer\n",
      "from nltk.stem.snowball import SnowballStemmer\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "class LemmaTokenizer(object):\n",
      "    def __init__(self):\n",
      "        self.wnl = WordNetLemmatizer()\n",
      "    def __call__(self, doc):\n",
      "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
      "\n",
      "class SnowballStemTokenizer(object):\n",
      "    def __init__(self):\n",
      "        self.stmr = SnowballStemmer('english')\n",
      "    def __call__(self, doc):\n",
      "        return [self.stmr.stem(t) for t in word_tokenize(doc)]\n",
      "    \n",
      "class PorterStemTokenizer(object):\n",
      "    def __init__(self):\n",
      "        self.stmr = PorterStemmer()\n",
      "    def __call__(self, doc):\n",
      "        return [self.stmr.stem(t) for t in word_tokenize(doc)]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_json_file(path):\n",
      "    with open(path) as f:\n",
      "        data = json.load(f)\n",
      "    return data\n",
      "\n",
      "def make_submission_csv(predictions, ids, submission_name, path = '../../predictions'):\n",
      "    with open(path+'/'+submission_name+'.csv', 'w') as csvfile:\n",
      "        field_names = ['request_id', 'requester_received_pizza']\n",
      "        writer = csv.DictWriter(csvfile, fieldnames = field_names)\n",
      "        writer.writeheader()\n",
      "        csv_data = zip(ids, predictions)\n",
      "        for row in csv_data:\n",
      "            writer.writerow({field_names[0]:row[0], field_names[1]:int(row[1])})\n",
      "\n",
      "def balance_samples(y, method='oversample'):\n",
      "    class_counts = np.bincount(y)\n",
      "    \n",
      "    maxi = np.argmax(class_counts)\n",
      "    new_idx = np.argwhere(y==maxi)\n",
      "    \n",
      "    for i in range(len(class_counts)):\n",
      "        if i != maxi:\n",
      "            mult = class_counts[maxi]/class_counts[i]\n",
      "            rem = class_counts[maxi] - class_counts[i]*mult\n",
      "            idxi = np.argwhere(y==i)\n",
      "            np.random.shuffle(idxi)\n",
      "            for j in range(mult):\n",
      "                new_idx = np.vstack((new_idx,idxi))\n",
      "            new_idx = np.vstack((new_idx,idxi[:rem]))\n",
      "        \n",
      "    np.random.shuffle(new_idx)\n",
      "\n",
      "    return np.reshape(new_idx, (new_idx.shape[0],))\n",
      "\n",
      "def oversample_kfold(kf, y):\n",
      "    kf_over = []\n",
      "    for ti, di in kf:\n",
      "        yt = y[ti]\n",
      "        ti_over = ti[balance_samples(yt)]\n",
      "        kf_over.append((ti_over, di))\n",
      "    return kf_over\n",
      "\n",
      "def name2index(df, names):\n",
      "    return_single = False\n",
      "    \n",
      "    if type(names) == type([]):\n",
      "       names = np.array(names)\n",
      "    elif type(names) != type(np.array([])):\n",
      "        names = np.array([names])\n",
      "        return_single = True \n",
      "    \n",
      "    inds = np.where(np.in1d(df.columns, np.array(names)))[0]\n",
      "    \n",
      "    return inds[0] if return_single else inds\n",
      "\n",
      "def print_scores(scores):\n",
      "    print 'N: %d, Mean: %f, Median: %f, SD: %f' %(len(scores), np.mean(scores), np.median(scores), np.std(scores))\n",
      "            \n",
      "def test_kfolds(X, y, kf, model, verbose=1, balance=False):\n",
      "    roc_auc_list = []\n",
      "    \n",
      "    for train_i, dev_i in kf:\n",
      "        if balance:\n",
      "            train_i_orig = train_i\n",
      "            y_train = y[train_i_orig]\n",
      "            train_i = train_i_orig[balance_samples(y_train)]\n",
      "        \n",
      "        \n",
      "        X_train = X[train_i]\n",
      "        X_dev = X[dev_i]\n",
      "\n",
      "        model.fit(X_train, y[train_i])\n",
      "\n",
      "        dev_pred = model.predict(X_dev)\n",
      "        \n",
      "        roc_auc_i = roc_auc_score(y[dev_i], dev_pred)\n",
      "        roc_auc_list.append(roc_auc_i)\n",
      "        if verbose > 1:\n",
      "            print('ROC AUC:',roc_auc_i)\n",
      "            \n",
      "    if verbose > 0:\n",
      "        print 'N: %d, Mean: %f, Median: %f, SD: %f' %(len(kf), np.mean(roc_auc_list), np.median(roc_auc_list), np.std(roc_auc_list))\n",
      "        \n",
      "    return roc_auc_list\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load data from JSON file as list of dicts\n",
      "all_train_dict_list = load_json_file('../../data/train.json')\n",
      "submit_dict_list =  load_json_file('../../data/test.json')\n",
      "\n",
      "n_all = len(all_train_dict_list)\n",
      "n_submit = len(submit_dict_list)\n",
      "\n",
      "# shuffle data to avoid biased split of train / dev data\n",
      "rand.shuffle(all_train_dict_list)\n",
      "\n",
      "# set up kFolds\n",
      "kf = KFold(n_all, n_folds = 5)\n",
      "\n",
      "# process labels\n",
      "all_train_labels = np.array([x['requester_received_pizza'] for x in all_train_dict_list])\n",
      "\n",
      "# pandas is useful for turning dicts in to matrix-like objects\n",
      "# where each column is an numpy array\n",
      "submit_df = pd.DataFrame(submit_dict_list)\n",
      "all_train_df = pd.DataFrame(all_train_dict_list)\n",
      "\n",
      "# limit train to columns available in submit_df\n",
      "submit_cols = submit_df.columns\n",
      "all_train_df = all_train_df[submit_cols]\n",
      "\n",
      "# useful for sklearn scoring\n",
      "roc_scorer = make_scorer(roc_auc_score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ACTIVITY_VARS = ['requester_account_age_in_days_at_request',\n",
      "                'requester_days_since_first_post_on_raop_at_request',\n",
      "                'requester_number_of_comments_at_request',\n",
      "                'requester_number_of_comments_in_raop_at_request',\n",
      "                'requester_number_of_posts_at_request',\n",
      "                'requester_number_of_posts_on_raop_at_request',\n",
      "                'requester_number_of_subreddits_at_request',\n",
      "                'requester_upvotes_minus_downvotes_at_request',\n",
      "                'requester_upvotes_plus_downvotes_at_request'\n",
      "                ]\n",
      "ACTIVITY_COLUMNS = name2index(all_train_df, ACTIVITY_VARS)\n",
      "TITLE_COLUMN = name2index(all_train_df, 'request_title')\n",
      "BODY_COLUMN = name2index(all_train_df, 'request_text_edit_aware')\n",
      "USER_NAME_COLUMN = name2index(all_train_df, 'requester_username')\n",
      "\n",
      "\n",
      "class ExtractColumnsTransformer(TransformerMixin):\n",
      "    \n",
      "    def __init__(self, cols=[0]):\n",
      "        self.cols = cols\n",
      "        \n",
      "    def fit(self, *args, **kwargs):\n",
      "        return self\n",
      "        \n",
      "    def transform(self, X):\n",
      "        cols = self.cols\n",
      "        return X[:,cols]\n",
      "    \n",
      "    def get_params(self, deep=True):\n",
      "        # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
      "        return {}\n",
      "\n",
      "    def set_params(self, **parameters):\n",
      "        for parameter, value in parameters.items():\n",
      "            self.setattr(parameter, value)\n",
      "        return self\n",
      "\n",
      "class ExtractActivities(ExtractColumnsTransformer):\n",
      "    def __init__(self):\n",
      "        ExtractColumnsTransformer.__init__(self, ACTIVITY_COLUMNS)\n",
      "\n",
      "class ExtractBody(ExtractColumnsTransformer):\n",
      "    def __init__(self):\n",
      "        ExtractColumnsTransformer.__init__(self, BODY_COLUMN)\n",
      "        \n",
      "\n",
      "class ExtractTitle(ExtractColumnsTransformer):\n",
      "    def __init__(self):\n",
      "        ExtractColumnsTransformer.__init__(self, TITLE_COLUMN)\n",
      "\n",
      "\n",
      "class ExtractUser(ExtractColumnsTransformer):\n",
      "    def __init__(self):\n",
      "        ExtractColumnsTransformer.__init__(self, USER_NAME_COLUMN)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DATE_TIME_COLUMN_DEFAULT = np.where(all_train_df.columns == 'unix_timestamp_of_request')[0][0]\n",
      "\n",
      "class TimeTransformer(TransformerMixin):\n",
      "    \n",
      "    def __init__(self, date_time_column=DATE_TIME_COLUMN_DEFAULT, do_hour=True, do_dow=True, do_month=True):\n",
      "        self.date_time_column = date_time_column\n",
      "        self.do_hour = do_hour\n",
      "        self.do_dow = do_dow\n",
      "        self.do_month = do_month\n",
      "        \n",
      "    def fit(self, X, y, **fit_params):\n",
      "        return self\n",
      "    \n",
      "    def extract_from_date_time_(self, dt, do_hour, do_dow, do_month):\n",
      "        extract = []\n",
      "        if do_hour:\n",
      "            extract.append(dt.hour)\n",
      "            \n",
      "        if do_dow:\n",
      "            extract.append(dt.weekday())\n",
      "            \n",
      "        if do_month:\n",
      "            extract.append(dt.month)\n",
      "            \n",
      "        return extract\n",
      "    \n",
      "    def transform(self, X, **transform_params):\n",
      "        date_time_column = self.date_time_column\n",
      "        do_hour = self.do_hour\n",
      "        do_dow = self.do_dow\n",
      "        do_month = self.do_month\n",
      "        extract_from_date_time = self.extract_from_date_time_\n",
      "        \n",
      "        features = np.array([\n",
      "            extract_from_date_time(dt.datetime.fromtimestamp(timei),\n",
      "                                   do_hour=do_hour,\n",
      "                                   do_dow=do_dow,\n",
      "                                   do_month=do_month) for timei in X[:,date_time_column]\n",
      "        ])\n",
      "        \n",
      "        return features\n",
      "    \n",
      "    def get_params(self, deep=True):\n",
      "        return {}\n",
      "\n",
      "    def set_params(self, **parameters):\n",
      "        for parameter, value in parameters.items():\n",
      "            self.setattr(parameter, value)\n",
      "        return self\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bodies = ExtractBody().transform(all_train_df.values)\n",
      "titles = ExtractTitle().transform(all_train_df.values)\n",
      "username = ExtractUser().transform(all_train_df.values)\n",
      "y = all_train_labels\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "choices = np.random.choice(np.arange(n_all),5)\n",
      "for i in choices:\n",
      "    print '###########################'\n",
      "    if y[i]:\n",
      "        print 'SUCCESS'\n",
      "    else:\n",
      "        print 'FAILURE'\n",
      "    \n",
      "    print 'User:', username[i]\n",
      "    \n",
      "    print 'Title:'\n",
      "    print titles[i]\n",
      "    \n",
      "    print 'Body:'\n",
      "    print bodies[i]\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "###########################\n",
        "FAILURE\n",
        "User: FratriarchofMorgan\n",
        "Title:\n",
        "[REQUEST] Houston redditor just moved into a new apt and broke with no food in pantry\n",
        "Body:\n",
        "Title says it all if you could help I would love you forever!!\n",
        "###########################\n",
        "SUCCESS\n",
        "User: WhitechapelPrime\n",
        "Title:\n",
        "[Request] Lexington KY (US). Would love to be able to eat some pizza today, or tonight.\n",
        "Body:\n",
        "Not really a sob story, just paid bills so I can't afford pizza for my wife and I. Really craving one. Thanks if anyone finds it in their heart to help out. :-)\n",
        "###########################\n",
        "FAILURE\n",
        "User: take7steps\n",
        "Title:\n",
        "[Request] High Bridge, NJ- It's my birthday!\n",
        "Body:\n",
        "I'd love a pizza for my birthday. I'm not going out anywhere and I have my two children who'd like some too. I don't have a car and the only place that delivers is Dominos. Thank you for reading, even if you can't donate! \n",
        "###########################\n",
        "SUCCESS\n",
        "User: brazen\n",
        "Title:\n",
        "[Request] Wedding anniversary tomorrow (6/28)\n",
        "Body:\n",
        "I live near Wichita and the wife and I (and three kids) are on a super tight budget right now.  She would be ecstatic to be surprised with a pizza!\n",
        "###########################\n",
        "FAILURE\n",
        "User: linford86\n",
        "Title:\n",
        "[REQUEST] Virginia USA Poor college student, no money to buy food at moment\n",
        "Body:\n",
        "Hey guys,\n",
        "\n",
        "I'm a student at Virginia Tech. Currently broke; would appreciate a pizza. Thanks!\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from urllib import urlopen"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TITLE_COLUMN = np.where(all_train_df.columns == 'request_title')[0][0]\n",
      "BODY_COLUMN = np.where(all_train_df.columns == 'request_text_edit_aware')[0][0]\n",
      "\n",
      "class LocationTransformer(TransformerMixin):\n",
      "    def __init__(self, title_col = TITLE_COLUMN, body_col=BODY_COLUMN, do_title=True, do_body=True, do_tags=True, do_words=True):\n",
      "        self.do_title = do_title\n",
      "        self.do_body = do_body\n",
      "        self.do_tags = do_tags\n",
      "        self.do_words = do_words\n",
      "        self.title_col = title_col\n",
      "        self.body_col = body_col\n",
      "        \n",
      "        self.keywords = {\n",
      "            'virginia':['virginia', 'VA']\n",
      "        }\n",
      "    \n",
      "    def find_tag_words(self, keywords, text):\n",
      "        word_dict = {}\n",
      "        tag_dict = {}\n",
      "\n",
      "        for tag, words in keywords.iteritems():\n",
      "\n",
      "            tag_count = None\n",
      "\n",
      "            for word in words:\n",
      "                has_word = np.array([(1 if word in t else 0) for t in text])\n",
      "                word_dict[word] = has_word\n",
      "\n",
      "                if tag_count is None:\n",
      "                    tag_count = has_word\n",
      "                else:\n",
      "                    tag_count = tag_count +  has_word\n",
      "\n",
      "            tag_dict[tag] = tag_count\n",
      "\n",
      "        return (tag_dict, word_dict)\n",
      "    \n",
      "    # manually create keywords with categories\n",
      "    \n",
      "    def transform(self, X, **transform_params):\n",
      "        do_title = self.do_title\n",
      "        do_tags = self.do_tags\n",
      "        do_words = self.do_words\n",
      "        do_body = self.do_body\n",
      "        keywords = self.keywords\n",
      "        find_tag_words = self.find_tag_words\n",
      "        body_col = self.body_col\n",
      "        title_col = self.title_col\n",
      "        \n",
      "        features = []\n",
      "        feature_names = []\n",
      "\n",
      "        # find keywords and tags\n",
      "        if do_title:\n",
      "            title_unicode = np.array([x.lower() for x in X[:,title_col]])\n",
      "            title_tag_dict, title_word_dict = find_tag_words(keywords, title_unicode)\n",
      "\n",
      "            if do_tags:\n",
      "                features.append(pd.DataFrame(title_tag_dict).values)\n",
      "                feature_names.append('title_tags')\n",
      "            if do_words:\n",
      "                features.append(pd.DataFrame(title_word_dict).values)\n",
      "                feature_names.append('title_words')\n",
      "\n",
      "        if do_body:\n",
      "            body_unicode = np.array([x.lower() for x in X[:,body_col]])\n",
      "            body_tag_dict, body_word_dict = find_tag_words(keywords, body_unicode)\n",
      "\n",
      "            if do_tags:\n",
      "                features.append(pd.DataFrame(body_tag_dict).values)\n",
      "                feature_names.append('body_tags')\n",
      "\n",
      "            if do_words:\n",
      "                features.append(pd.DataFrame(body_word_dict).values)\n",
      "                feature_names.append('body_words')\n",
      "\n",
      "        return np.hstack(tuple(features))\n",
      "    \n",
      "    def fit(self, X, y, **fit_params):\n",
      "        #do nothing\n",
      "        return self\n",
      "    \n",
      "    def get_params(self, deep=True):\n",
      "        return {'do_words': self.do_words, 'do_tags':self.do_tags, 'do_body':self.do_body, 'do_title':self.do_title}\n",
      "\n",
      "    def set_params(self, **parameters):\n",
      "        for parameter, value in parameters.items():\n",
      "            self.setattr(parameter, value)\n",
      "        return self\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_train_df.iloc[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "giver_username_if_known                                                                             N/A\n",
        "request_id                                                                                     t3_ixx2j\n",
        "request_text_edit_aware                               Hi ROAP! I am going through a rough time right...\n",
        "request_title                                                          [REQUEST] Hungry in Pennsylvania\n",
        "requester_account_age_in_days_at_request                                                              0\n",
        "requester_days_since_first_post_on_raop_at_request                                                    0\n",
        "requester_number_of_comments_at_request                                                               0\n",
        "requester_number_of_comments_in_raop_at_request                                                       0\n",
        "requester_number_of_posts_at_request                                                                  0\n",
        "requester_number_of_posts_on_raop_at_request                                                          0\n",
        "requester_number_of_subreddits_at_request                                                             0\n",
        "requester_subreddits_at_request                                                                      []\n",
        "requester_upvotes_minus_downvotes_at_request                                                          0\n",
        "requester_upvotes_plus_downvotes_at_request                                                           0\n",
        "requester_username                                                                           johnny2by4\n",
        "unix_timestamp_of_request                                                                   1.31146e+09\n",
        "unix_timestamp_of_request_utc                                                              1.311456e+09\n",
        "Name: 0, dtype: object"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}